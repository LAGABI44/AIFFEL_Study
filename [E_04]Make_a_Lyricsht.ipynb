{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52mhDwdRBI9_"
      },
      "source": [
        "# í”„ë¡œì íŠ¸4 : Scikit-learnì˜ Toy Dataset í™œìš©\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##<ëª©ì°¨>\n",
        "Step 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ   \n",
        "Step 2. ë°ì´í„° ì½ì–´ì˜¤ê¸°   \n",
        "Step 3. ë°ì´í„° ì •ì œ   \n",
        "- íŠ¹ìˆ˜ë¬¸ì ì œê±°   \n",
        "- ì •ê·œí‘œí˜„ì‹ ë°ì´í„° ì •ì œ   \n",
        "- [ë²ˆì™¸]ê¸°íƒ€ ì‹¤í—˜   \n",
        "\n",
        "Step 4. í‰ê°€ ë°ì´í„°ì…‹ ë¶„ë¦¬   \n",
        "- í† í¬ë‚˜ì´ì € ìƒì„±   \n",
        "- í…ì„œí”Œë¡œìš° í™œìš© ë°ì´í„° ë¶„ë¦¬   \n",
        "\n",
        "Step 5. ì¸ê³µì§€ëŠ¥ ë§Œë“¤ê¸°   \n",
        "- ìµœì¢… ëª¨ë¸ í•™ìŠµ(ğŸ‰ğŸ‰ì™„ë²½ ì„±ê³µğŸ‰ğŸ‰)\n",
        "- validation loss 2.2 ì´í•˜ë¥¼ ìœ„í•œ ë…¸ë ¥ì˜ í”ì \n",
        "\n",
        "Step 6. ì‘ë¬¸ í‰ê°€   \n",
        "Step 7. íšŒê³    \n",
        "Step 8. Reference"
      ],
      "metadata": {
        "id": "2AivGxJp_aAr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ"
      ],
      "metadata": {
        "id": "1emLx0ZD5zP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir -p ~/content/lyricist/models\n",
        "! ln -s ~/data ~/content/lyricist/data"
      ],
      "metadata": {
        "id": "FBu2k5qlmvoA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 2. ë°ì´í„° ì½ì–´ì˜¤ê¸°"
      ],
      "metadata": {
        "id": "Ke1SfF6B5-2Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIvx7NVjA882",
        "outputId": "e591ffcb-8816-4979-ddcf-d7bee863c61c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ë°ì´í„° í¬ê¸°: 187088\n",
            "Examples:\n",
            " ['Can we forget about the things I said when I was drunk...', \"I didn't mean to call you that\", \"I can't remember what was said\"]\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "\n",
        "txt_file_path = '/content/lyricist/data/lyrics/*'\n",
        "\n",
        "txt_list = glob.glob(txt_file_path)\n",
        "\n",
        "raw_corpus = []\n",
        "\n",
        "# ì—¬ëŸ¬ê°œì˜ txt íŒŒì¼ì„ ëª¨ë‘ ì½ì–´ì„œ raw_corpus ì— ë‹´ìŠµë‹ˆë‹¤.\n",
        "for txt_file in txt_list:\n",
        "    with open(txt_file, \"r\") as f:\n",
        "        raw = f.read().splitlines()\n",
        "        raw_corpus.extend(raw)\n",
        "\n",
        "print(\"ë°ì´í„° í¬ê¸°:\", len(raw_corpus))\n",
        "print(\"Examples:\\n\", raw_corpus[:3])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 3. ë°ì´í„° ì •ì œ\n",
        "###**íŠ¹ìˆ˜ë¬¸ì ì œê±°**"
      ],
      "metadata": {
        "id": "EVuQaMvO6BBs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ytMGFbfX2s_W",
        "outputId": "bf6f22b8-19a1-4d2b-9d41-4d85b93e3ff3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> this is sample sentence . <end>\n"
          ]
        }
      ],
      "source": [
        "#ì •ê·œí‘œí˜„ì‹ ì •ì œ\n",
        "import os, re \n",
        "\n",
        "def preprocess_sentence(sentence):\n",
        "    sentence = sentence.lower().strip() # 1\n",
        "    sentence = re.sub(r\"([?.!,Â¿])\", r\" \\1 \", sentence) # 2\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,Â¿]+\", \" \", sentence) # 4\n",
        "    sentence = sentence.strip() # 5\n",
        "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
        "    return sentence\n",
        "\n",
        "# ì´ ë¬¸ì¥ì´ ì–´ë–»ê²Œ í•„í„°ë§ë˜ëŠ”ì§€ í™•ì¸í•´ ë³´ì„¸ìš”.\n",
        "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**ì •ê·œí‘œí˜„ì‹ ë°ì´í„° ì •ì œ**"
      ],
      "metadata": {
        "id": "w613rIk3vdH4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIPbCQTuBq4m",
        "outputId": "26d4fa36-307e-437d-eb5c-e32d30952c4b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> the unsuspecting victim of darkness in the valley <end>',\n",
              " '<start> we can live like jack and sally if we want <end>',\n",
              " '<start> where you can always find me <end>',\n",
              " '<start> and we ll have halloween on christmas <end>',\n",
              " '<start> and in the night we ll wish this never ends <end>',\n",
              " '<start> we ll wish this never ends i miss you i miss you <end>',\n",
              " '<start> i miss you i miss you where are you and i m so sorry <end>',\n",
              " '<start> i cannot sleep i cannot dream tonight <end>',\n",
              " '<start> i need somebody and always <end>',\n",
              " '<start> this sick strange darkness <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ],
      "source": [
        "# ì •ê·œí‘œí˜„ì‹ ë°ì´í„° ì •ì œ\n",
        "\n",
        "corpus = []  #ì •ì œí•œ ë°ì´í„°ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•¨\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    # ìš°ë¦¬ê°€ ì›í•˜ì§€ ì•ŠëŠ” ë¬¸ì¥ì€ ê±´ë„ˆëœë‹ˆë‹¤\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    # ì •ì œë¥¼ í•˜ê³  ë‹´ì•„ì£¼ì„¸ìš”\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    if preprocessed_sentence.count(' ') > 15 : continue\n",
        "    corpus.append(preprocessed_sentence)\n",
        "\n",
        "    #ì˜ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "corpus[140:150]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**[ë²ˆì™¸]ê¸°íƒ€ ì‹¤í—˜**"
      ],
      "metadata": {
        "id": "bKaIfmOlvDl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIsxgLKn34Y3",
        "outputId": "11366eb2-41e9-4fe9-baa7-1959a9f7ea55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> don t waste your time on me you re already <end>',\n",
              " '<start> the voice inside my head i miss you , miss you <end>',\n",
              " '<start> don t waste your time on me you re already <end>',\n",
              " '<start> the voice inside my head i miss you , miss you <end>',\n",
              " '<start> don t waste your time on me you re already <end>',\n",
              " '<start> the voice inside my head i miss you , miss you <end>',\n",
              " '<start> i miss you , miss you <end>',\n",
              " '<start> i miss you , miss you <end>',\n",
              " '<start> i miss you , miss you <end>',\n",
              " '<start> i miss you , miss you i miss you miss you hello there the angel from my nightmare <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "#<ë²ˆì™¸-ë¹„êµ ëŒ€ìƒêµ°>\n",
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    # ìš°ë¦¬ê°€ ì›í•˜ì§€ ì•ŠëŠ” ë¬¸ì¥ì€ ê±´ë„ˆëœë‹ˆë‹¤\n",
        "    if len(sentence) == 0: continue\n",
        "    if sentence[-1] == \":\": continue\n",
        "    \n",
        "    # ì •ì œë¥¼ í•˜ê³  ë‹´ì•„ì£¼ì„¸ìš”\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "\n",
        "    #ì˜ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸ / ë‹¨ì–´ 15ê°œ ë„˜ëŠ” ë¬¸ì¥ ì°¾ëŠ”ë‹¤ê³  ë…¸ê°€ë‹¤í•¨ã… ã… \n",
        "corpus[140:150]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRvECXhJAyjB",
        "outputId": "f7958f61-1582-4228-8dae-2eb1a47526d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> all around you <end>',\n",
              " '<start> that he s in <end>',\n",
              " '<start> to a shadow <end>',\n",
              " '<start> and i wonder <end>',\n",
              " '<start> silvio <end>',\n",
              " '<start> silver and gold <end>',\n",
              " '<start> silvio <end>',\n",
              " '<start> i gotta go <end>',\n",
              " '<start> silvio <end>',\n",
              " '<start> silver and gold <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#<ë²ˆì™¸-len()1>\n",
        "corpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    # ìš°ë¦¬ê°€ ì›í•˜ì§€ ì•ŠëŠ” ë¬¸ì¥ì€ ê±´ë„ˆëœë‹ˆë‹¤\n",
        "    if len(sentence) == 0: continue\n",
        "      #í† í°ì˜ ê°œìˆ˜ê°€ 15ê°œë¥¼ ë„˜ì–´ê°€ëŠ” ë¬¸ì¥ì„ í•™ìŠµ ë°ì´í„°ì—ì„œ ì œì™¸\n",
        "    if sentence[-1] == \":\": continue\n",
        "    if len(sentence) > 15: continue\n",
        "\n",
        "    # ì •ì œë¥¼ í•˜ê³  ë‹´ì•„ì£¼ì„¸ìš”\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "\n",
        "    #ì˜ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "corpus[140:150]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eeo23WMrA761",
        "outputId": "2bc2f841-6c3a-4edb-e445-d3fe5de4fb97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['<start> ok a millie sold first day i went gold how do i celebrate work on the carter <end>',\n",
              " '<start> yup i aint here to brag nor boast this is simply an attempt to thank you <end>',\n",
              " '<start> the most <end>',\n",
              " '<start> you the fan you the man and to my female audience i hope you use sanitizer <end>',\n",
              " '<start> cuz im kissin all ya hands <end>',\n",
              " '<start> all my plans is well executed <end>',\n",
              " '<start> this that electric music you can get electrocuted <end>',\n",
              " '<start> you know i extra do it they say im the best to do <end>',\n",
              " '<start> i say im better than who next to do it or whoever do it <end>',\n",
              " '<start> they could never do it like me i c o n or you could call me mr i go in <end>']"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#<ë²ˆì™¸-len()2>\n",
        "orpus = []\n",
        "\n",
        "for sentence in raw_corpus:\n",
        "    # ìš°ë¦¬ê°€ ì›í•˜ì§€ ì•ŠëŠ” ë¬¸ì¥ì€ ê±´ë„ˆëœë‹ˆë‹¤\n",
        "    if len(sentence) == 0: continue\n",
        "      #í† í°ì˜ ê°œìˆ˜ê°€ 15ê°œë¥¼ ë„˜ì–´ê°€ëŠ” ë¬¸ì¥ì„ í•™ìŠµ ë°ì´í„°ì—ì„œ ì œì™¸\n",
        "    if sentence[-1] == \":\": continue\n",
        "    if len(sentence.split()) > 15: continue\n",
        "\n",
        "    # ì •ì œë¥¼ í•˜ê³  ë‹´ì•„ì£¼ì„¸ìš”\n",
        "    preprocessed_sentence = preprocess_sentence(sentence)\n",
        "    corpus.append(preprocessed_sentence)\n",
        "\n",
        "    #ì˜ ì ìš©ë˜ì—ˆëŠ”ì§€ í™•ì¸\n",
        "corpus[140:150]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "â— í† í° 15ê°œ ì´ìƒ ì»·ì´ ì˜ ì§„í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸ì„ ìœ„í•´ ì‹¤í—˜   \n",
        "1ë²ˆì§¸ë¶€í„° 139ë²ˆì§¸ê¹Œì§€ ë‹¨ì–´ 15ê°œ ì´ìƒì˜ ë¬¸ì¥ì´ ì—†ì–´ì„œ ë…¸ê°€ë‹¤ë¡œ ë‹¨ì–´ 15ê°œ ì´ìƒì˜ ë¬¸ì¥ì´ ë‚˜ì˜¬ ë•Œê¹Œì§€ ì°¾ì•„ë´„   \n",
        "ê·¸ë¦¬í•˜ì—¬ corpus[140:150] ìœ¼ë¡œ ì½”ë“œ ë¹„êµë¥¼ í•´ë´„   \n",
        "ì²˜ìŒì—ëŠ” counterë¥¼ ì‚¬ìš©í•˜ì—¬ ì»·í•˜ë ¤ê³  í–ˆìœ¼ë‚˜ ì•„ì§ ì‚¬ìš©ë²•ì´ ë¯¸ìˆ™í•˜ì—¬ ê³„ì† ì˜¤ë¥˜ê°€ ë‚¨ -> ì°¾ì•„ë³´ì•˜ìœ¼ë‚˜ ì™„ë²½íˆ ì´í•´ëŠ” í•˜ì§€ ëª»í•¨   \n",
        "ê·¸ë˜ì„œ ê°€ì¥ í†µìƒì ìœ¼ë¡œ ë§ì´ ì‚¬ìš©í•˜ëŠ” lenì„ ì´ìš©í•¨ -> ì²˜ìŒì—ëŠ” ë³„ ë¬¸ì œê°€ ì—†ì–´ë³´ì˜€ìœ¼ë‚˜ corpus[140:150]ì„ í†µí•´ ë¬¸ì¥ì„ í™•ì¸í•´ë³´ë‹ˆ ë¬¸ì¥ì´ ì´ìƒí•˜ê²Œ ì˜ë¦¼ì„ ë°œê²¬\n",
        "ê·¸ë˜ì„œ ì—¬ëŸ¬ ë°©ë²•ì„ ì‹œë„í•œ í›„ count ë¡œ ê°€ì¥ ì í•©í•˜ê²Œ ì»·ì„ í•¨."
      ],
      "metadata": {
        "id": "TN_mcD5jvxHE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 4. í‰ê°€ ë°ì´í„°ì…‹ ë¶„ë¦¬\n",
        "### **í† í¬ë‚˜ì´ì € ìƒì„±**\n",
        "\n",
        ": ë¬¸ì¥ì„ ì¼ì •í•œ ê¸°ì¤€ìœ¼ë¡œ ìª¼ê°œëŠ” ê³¼ì •\n",
        "\n",
        "- ë¬¸ì¥ì˜ ìµœëŒ€ê¸¸ì´ë¥¼ 15ë¡œ ì„¤ì •\n",
        "- ìµœëŒ€ê¸¸ì´ê°€ 15ë³´ë‹¤ ì‘ìœ¼ë©´ paddingê°’ìœ¼ë¡œ ëŒ€ì²´(padding=0)\n",
        "- ìµœëŒ€ê¸¸ì´ê°€ 15ë³´ë‹¤ í¬ë©´ ë’· ë¶€ë¶„ ì œê±°"
      ],
      "metadata": {
        "id": "5OAmvgoQ6LiI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly7I13BRBM1V",
        "outputId": "b06fe3dd-22a9-4e96-f96b-30a97f1b76a3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  2   4 375 ...   0   0   0]\n",
            " [  2   4  35 ...   0   0   0]\n",
            " [  2 106  39 ...   0   0   0]\n",
            " ...\n",
            " [  2   3   0 ...   0   0   0]\n",
            " [  2   3   0 ...   0   0   0]\n",
            " [  2   3   0 ...   0   0   0]] <keras_preprocessing.text.Tokenizer object at 0x7ff31c58bc90>\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "def tokenize(corpus):\n",
        "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "        num_words=12000, #ë‹¨ì–´ì¥ì˜ ê°œìˆ˜\n",
        "        filters=' ',    #ì“°ì§€ ì•Šê² ë‹¤. ìœ„ì—ì„œ í•œ ë²ˆ ì •ì œí–ˆê¸° ë•Œë¬¸ì— í•„í„°ëŠ” ì‚¬ì‹¤ìƒ í•„ìš”ê°€ ì—†ë‹¤, ì• ì´ˆì— ì „ì²˜ë¦¬ë¥¼ ìœ„í•´ì„œ í•„ìš”í•œ ì•„ì´\n",
        "        oov_token=\"<unk>\"    #12000ë‹¨ì–´ì— í¬í•¨ë˜ì§€ ëª»í•œ ë‹¨ì–´ëŠ” '<unk>'ë¡œ ë°”ê¾¸ê¸°\n",
        "    )\n",
        "    # corpusë¥¼ ì´ìš©í•´ tokenizer ë‚´ë¶€ì˜ ë‹¨ì–´ì¥ì„ ì™„ì„±í•©ë‹ˆë‹¤\n",
        "    tokenizer.fit_on_texts(corpus)\n",
        "    # ì¤€ë¹„í•œ tokenizerë¥¼ ì´ìš©í•´ corpusë¥¼ Tensorë¡œ ë³€í™˜í•©ë‹ˆë‹¤\n",
        "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
        "    # ì…ë ¥ ë°ì´í„°ì˜ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì¼ì •í•˜ê²Œ ë§ì¶°ì¤ë‹ˆë‹¤\n",
        "    # ë§Œì•½ ì‹œí€€ìŠ¤ê°€ ì§§ë‹¤ë©´ ë¬¸ì¥ ë’¤ì— íŒ¨ë”©ì„ ë¶™ì—¬ ê¸¸ì´ë¥¼ ë§ì¶°ì¤ë‹ˆë‹¤.\n",
        "    # ë¬¸ì¥ ì•ì— íŒ¨ë”©ì„ ë¶™ì—¬ ê¸¸ì´ë¥¼ ë§ì¶”ê³  ì‹¶ë‹¤ë©´ padding='pre'ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤\n",
        "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post', maxlen=15)  \n",
        "    \n",
        "    print(tensor,tokenizer)\n",
        "    return tensor, tokenizer\n",
        "\n",
        "tensor, tokenizer = tokenize(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYSIwzEKL3vH"
      },
      "source": [
        "### **í…ì„œí”Œë¡œìš° í™œìš© ë°ì´í„° ë¶„ë¦¬**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2L554BlqL7SO",
        "outputId": "eb2ef3f9-f05b-4a64-88f6-c6667203764d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  2   4 375  16 251  10 152   7  15   3   0   0   0   0]\n",
            "[  4 375  16 251  10 152   7  15   3   0   0   0   0   0]\n"
          ]
        }
      ],
      "source": [
        "src_input = tensor[:, :-1]   # tensorì—ì„œ ë§ˆì§€ë§‰ í† í°ì„ ì˜ë¼ë‚´ì„œ ì†ŒìŠ¤ ë¬¸ì¥ì„ ìƒì„±\n",
        "tgt_input = tensor[:, 1:]    # tensorì—ì„œ <start>ë¥¼ ì˜ë¼ë‚´ì„œ íƒ€ê²Ÿ ë¬¸ì¥ì„ ìƒì„±\n",
        "\n",
        "print(src_input[0])\n",
        "print(tgt_input[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2E7OOV_CQb85",
        "outputId": "af65995a-da5f-4edb-945b-213cbf2240ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Source Train: (128205, 14)\n",
            "Target Train: (128205, 14)\n"
          ]
        }
      ],
      "source": [
        "#trainê³¼ Test(val) ë¶„ë¦¬\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# lms ì§€ì‹œ\n",
        "#ì´ ë°ì´í„°ì˜ 20% ë¥¼ í‰ê°€ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‚¬ìš©í•´ ì£¼ì„¸ìš”!\n",
        "\n",
        "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size=0.2)\n",
        "#ì„ì„ ì´ìœ ê°€ ì—†ê¸° ë•Œë¬¸ì— random_stateëŠ” ì‚¬ìš©í•˜ì§€ ì•Šê² ë‹¤.\n",
        "\n",
        "print(\"Source Train:\", enc_train.shape)\n",
        "print(\"Target Train:\", dec_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tr8FgwY5VDb-",
        "outputId": "0a2369b8-0974-4fed-cccc-234719257db9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BatchDataset shapes: ((64, 14), (64, 14)), types: (tf.int32, tf.int32)>"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "#ë°ì´í„°ì…‹ ì •ì˜í•˜ê¸°, ê°ì²´ ìƒì„±\n",
        "\n",
        "BUFFER_SIZE = len(enc_train)\n",
        "BATCH_SIZE = 64\n",
        "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
        "\n",
        " # tokenizerê°€ êµ¬ì¶•í•œ ë‹¨ì–´ì‚¬ì „ ë‚´ 12000ê°œì™€, ì—¬ê¸° í¬í•¨ë˜ì§€ ì•Šì€ 0:<pad>ë¥¼ í¬í•¨í•˜ì—¬ 7001ê°œ\n",
        "VOCAB_SIZE = tokenizer.num_words + 1   \n",
        "\n",
        "# ì¤€ë¹„í•œ ë°ì´í„° ì†ŒìŠ¤ë¡œë¶€í„° ë°ì´í„°ì…‹ì„ ë§Œë“­ë‹ˆë‹¤\n",
        "# ë°ì´í„°ì…‹ì— ëŒ€í•´ì„œëŠ” ì•„ë˜ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì„¸ìš”\n",
        "# ìì„¸íˆ ì•Œì•„ë‘˜ìˆ˜ë¡ ë„ì›€ì´ ë§ì´ ë˜ëŠ” ì¤‘ìš”í•œ ë¬¸ì„œì…ë‹ˆë‹¤\n",
        "# https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tbDLUQNUjtW"
      },
      "source": [
        "### Step 5. ì¸ê³µì§€ëŠ¥ ë§Œë“¤ê¸°"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxewN30YWcWi",
        "outputId": "249dba41-0929-411c-88be-aef1080ffb52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 14, 12001), dtype=float32, numpy=\n",
              "array([[[ 4.4040549e-05,  4.0495541e-04, -1.2976209e-04, ...,\n",
              "         -8.5205495e-05, -8.3998137e-05, -3.6425921e-04],\n",
              "        [ 1.1136556e-04,  3.2280807e-04, -5.1000941e-04, ...,\n",
              "         -4.6400796e-04, -3.4815349e-04, -6.4714014e-04],\n",
              "        [ 6.4323033e-04, -1.0870084e-04, -7.2515791e-04, ...,\n",
              "         -9.9677290e-04, -5.0296797e-04, -1.2085245e-03],\n",
              "        ...,\n",
              "        [ 4.5412159e-04, -3.0151508e-03,  1.4298427e-03, ...,\n",
              "         -2.0543844e-03,  5.2642409e-04, -2.6084161e-03],\n",
              "        [-3.5977871e-05, -3.5673396e-03,  2.3289821e-03, ...,\n",
              "         -2.5781200e-03,  9.7355398e-04, -2.4842490e-03],\n",
              "        [-4.9672951e-04, -4.0722392e-03,  3.0743345e-03, ...,\n",
              "         -3.0731484e-03,  1.4088321e-03, -2.3290243e-03]],\n",
              "\n",
              "       [[ 4.4040549e-05,  4.0495541e-04, -1.2976209e-04, ...,\n",
              "         -8.5205495e-05, -8.3998137e-05, -3.6425921e-04],\n",
              "        [ 2.3893047e-04,  4.5186878e-04, -3.7188581e-04, ...,\n",
              "          4.4418457e-06,  3.5794321e-04, -4.2084628e-04],\n",
              "        [ 4.9827789e-04,  5.3693965e-04, -5.6843512e-04, ...,\n",
              "         -4.0878303e-06,  3.5417895e-04, -7.3265203e-04],\n",
              "        ...,\n",
              "        [-1.8767819e-03, -3.7566859e-03,  4.6499879e-03, ...,\n",
              "         -4.3475828e-03,  2.5870495e-03, -8.1215467e-04],\n",
              "        [-2.0796349e-03, -4.1711186e-03,  4.8167566e-03, ...,\n",
              "         -4.5915847e-03,  2.6326554e-03, -8.3734246e-04],\n",
              "        [-2.2454828e-03, -4.5258095e-03,  4.9316026e-03, ...,\n",
              "         -4.7785244e-03,  2.6496470e-03, -8.7540108e-04]],\n",
              "\n",
              "       [[ 4.4040549e-05,  4.0495541e-04, -1.2976209e-04, ...,\n",
              "         -8.5205495e-05, -8.3998137e-05, -3.6425921e-04],\n",
              "        [ 4.1070755e-04,  1.1126084e-03, -1.0550249e-04, ...,\n",
              "          2.5052495e-05, -2.3921307e-04, -4.1099943e-04],\n",
              "        [ 9.1255858e-04,  1.1550861e-03, -1.6135289e-04, ...,\n",
              "          6.3978229e-04, -2.8264066e-04, -2.9395171e-04],\n",
              "        ...,\n",
              "        [-4.8298895e-04, -8.0636708e-04,  4.2847754e-03, ...,\n",
              "          3.7482750e-04, -1.9302763e-04, -5.3138232e-05],\n",
              "        [-7.8157050e-04, -1.5628138e-03,  4.7944603e-03, ...,\n",
              "         -3.0092979e-04,  4.6251575e-04, -8.9562724e-05],\n",
              "        [-1.0694014e-03, -2.2964368e-03,  5.1614176e-03, ...,\n",
              "         -9.8031631e-04,  1.0629797e-03, -1.2346754e-04]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ 4.4040549e-05,  4.0495541e-04, -1.2976209e-04, ...,\n",
              "         -8.5205495e-05, -8.3998137e-05, -3.6425921e-04],\n",
              "        [-8.7332046e-05,  8.0425700e-04, -7.4447953e-04, ...,\n",
              "         -2.0981977e-04,  9.0922971e-05, -5.8410974e-04],\n",
              "        [ 5.6866345e-05,  7.2131981e-04, -5.6397996e-04, ...,\n",
              "         -4.5568254e-04, -1.7932200e-04, -7.3786464e-04],\n",
              "        ...,\n",
              "        [-4.0654308e-04, -1.7426375e-03,  3.1557372e-03, ...,\n",
              "         -2.9359516e-03, -8.0758058e-05, -2.3644373e-03],\n",
              "        [-8.2915818e-04, -2.3569253e-03,  3.7468788e-03, ...,\n",
              "         -3.3553164e-03,  4.8727839e-04, -2.2246765e-03],\n",
              "        [-1.2219476e-03, -2.9304596e-03,  4.1946261e-03, ...,\n",
              "         -3.7214400e-03,  1.0003102e-03, -2.0631407e-03]],\n",
              "\n",
              "       [[ 4.4040549e-05,  4.0495541e-04, -1.2976209e-04, ...,\n",
              "         -8.5205495e-05, -8.3998137e-05, -3.6425921e-04],\n",
              "        [ 3.0918664e-04,  4.3620694e-05, -1.1617196e-03, ...,\n",
              "         -7.8405676e-05, -1.9131892e-04, -8.0507476e-04],\n",
              "        [ 8.1304897e-04, -3.1002655e-05, -1.7767978e-03, ...,\n",
              "         -9.1375063e-05, -2.6632228e-04, -1.3809731e-04],\n",
              "        ...,\n",
              "        [ 2.5906521e-04, -1.0790542e-03,  2.8396907e-04, ...,\n",
              "         -1.3039388e-03,  1.9123807e-03, -8.5871601e-05],\n",
              "        [-2.3270372e-04, -1.5985116e-03,  1.3622572e-03, ...,\n",
              "         -1.8551963e-03,  2.1845289e-03, -1.8214916e-04],\n",
              "        [-7.0243597e-04, -2.1608227e-03,  2.2888673e-03, ...,\n",
              "         -2.4211891e-03,  2.4651689e-03, -2.5049940e-04]],\n",
              "\n",
              "       [[ 4.4040549e-05,  4.0495541e-04, -1.2976209e-04, ...,\n",
              "         -8.5205495e-05, -8.3998137e-05, -3.6425921e-04],\n",
              "        [ 1.2250767e-04,  9.1734459e-04,  9.6462267e-05, ...,\n",
              "          1.0723666e-04, -5.2027038e-04, -1.1176502e-03],\n",
              "        [ 5.1188923e-04,  1.3405693e-03, -1.6406006e-05, ...,\n",
              "          1.1108048e-04, -1.2195706e-03, -1.3238630e-03],\n",
              "        ...,\n",
              "        [-3.1402099e-04,  1.0175784e-03, -2.5049073e-04, ...,\n",
              "         -1.3671798e-03, -4.3510753e-04, -5.3689186e-04],\n",
              "        [-2.7599239e-05,  8.1236480e-04, -4.6884763e-04, ...,\n",
              "         -8.7388558e-04, -5.7912513e-04, -7.2586694e-04],\n",
              "        [ 3.0117662e-04,  4.7954894e-04, -4.1766989e-04, ...,\n",
              "         -5.7607802e-04, -9.1619539e-04, -1.0620682e-03]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "class TextGenerator(tf.keras.Model):\n",
        "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
        "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
        "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
        "        \n",
        "    def call(self, x):\n",
        "        out = self.embedding(x)\n",
        "        out = self.rnn_1(out)\n",
        "        out = self.rnn_2(out)\n",
        "        out = self.linear(out)\n",
        "        \n",
        "        return out\n",
        "    \n",
        "embedding_size = 1024    #ë‹¨ì–´ í•˜ë‚˜ì˜ íŠ¹ì§• ìˆ˜\n",
        "hidden_size = 2048    #í¼ì…‰íŠ¸ë¡ ì˜ ê°œìˆ˜\n",
        "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)\n",
        "\n",
        "\n",
        "for src_sample, tgt_sample in dataset.take(1): break\n",
        "\n",
        "# í•œ ë°°ì¹˜ë§Œ ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ë¥¼ ëª¨ë¸ì— ë„£ì–´ë´…ë‹ˆë‹¤\n",
        "model(src_sample)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bcb2C-e8Y6Nc",
        "outputId": "e93eb657-b0c0-4adc-e577-65cd3d78f5c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"text_generator_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_11 (Embedding)    multiple                  12289024  \n",
            "                                                                 \n",
            " lstm_22 (LSTM)              multiple                  25174016  \n",
            "                                                                 \n",
            " lstm_23 (LSTM)              multiple                  33562624  \n",
            "                                                                 \n",
            " dense_11 (Dense)            multiple                  24590049  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 95,615,713\n",
            "Trainable params: 95,615,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**ìµœì¢… ëª¨ë¸ í•™ìŠµ(ğŸ‰ğŸ‰ì™„ë²½ ì„±ê³µğŸ‰ğŸ‰)**"
      ],
      "metadata": {
        "id": "7zFBzOnZeTx2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ì•„í™‰ ë²ˆì§¸ ì‹œë„í•œ ëª¨ë¸ í•™ìŠµ\n",
        "# num_words 12000, batch_size=64\n",
        "# embedding_size = 1024\n",
        "#hidden_size = 2048\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(enc_train, dec_train,epochs=5, batch_size=64, validation_data=(enc_val, dec_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opODjJO0IOX6",
        "outputId": "1e0396a7-5386-4709-b090-367d4e4d988b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "2004/2004 [==============================] - 362s 179ms/step - loss: 3.0385 - val_loss: 2.7356\n",
            "Epoch 2/5\n",
            "2004/2004 [==============================] - 356s 178ms/step - loss: 2.4752 - val_loss: 2.4634\n",
            "Epoch 3/5\n",
            "2004/2004 [==============================] - 367s 183ms/step - loss: 2.0433 - val_loss: 2.3017\n",
            "Epoch 4/5\n",
            "2004/2004 [==============================] - 367s 183ms/step - loss: 1.6700 - val_loss: 2.2180\n",
            "Epoch 5/5\n",
            "2004/2004 [==============================] - 356s 178ms/step - loss: 1.3867 - val_loss: 2.1995\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff190f6d390>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###**validation loss 2.2 ì´í•˜ë¥¼ ìœ„í•œ ë…¸ë ¥ì˜ í”ì **\n",
        "ì•„ë˜ ë¶€ë¶„ì€ ëª¨ë¸ í•™ìŠµë„ ê¸°ë¡í•˜ê³ ì ê·¸ëŒ€ë¡œ ë‘ì—ˆìŠµë‹ˆë‹¤.   \n",
        "íŒ¨ìŠ¤í•˜ì…”ë„ ë©ë‹ˆë‹¤."
      ],
      "metadata": {
        "id": "4Z_9ZjsGeY2w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gy0nTLb1Z3yE",
        "outputId": "9a311b0f-2d46-4232-ec8e-c433c4299655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "251/251 [==============================] - 156s 606ms/step - loss: 2.3093 - val_loss: 2.5962\n",
            "Epoch 2/10\n",
            "251/251 [==============================] - 159s 633ms/step - loss: 2.2174 - val_loss: 2.5835\n",
            "Epoch 3/10\n",
            "251/251 [==============================] - 151s 601ms/step - loss: 2.1552 - val_loss: 2.5713\n",
            "Epoch 4/10\n",
            "251/251 [==============================] - 151s 601ms/step - loss: 2.0977 - val_loss: 2.5628\n",
            "Epoch 5/10\n",
            "251/251 [==============================] - 159s 633ms/step - loss: 2.0426 - val_loss: 2.5578\n",
            "Epoch 6/10\n",
            "251/251 [==============================] - 151s 601ms/step - loss: 1.9896 - val_loss: 2.5499\n",
            "Epoch 7/10\n",
            "251/251 [==============================] - 159s 633ms/step - loss: 1.9385 - val_loss: 2.5458\n",
            "Epoch 8/10\n",
            "251/251 [==============================] - 151s 600ms/step - loss: 1.8891 - val_loss: 2.5406\n",
            "Epoch 9/10\n",
            "251/251 [==============================] - 151s 601ms/step - loss: 1.8407 - val_loss: 2.5374\n",
            "Epoch 10/10\n",
            "251/251 [==============================] - 151s 600ms/step - loss: 1.7932 - val_loss: 2.5320\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f5580329f50>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# ì²« ë²ˆì§¸ ì‹œë„í•œ ëª¨ë¸ í•™ìŠµ\n",
        "# num_words 12000, batch_size=512\n",
        "#embedding_size = 256\n",
        "#hidden_size = 1024\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(enc_train, dec_train,epochs=10, batch_size=512, validation_data=(enc_val, dec_val))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‘ ë²ˆì§¸ ì‹œë„í•œ ëª¨ë¸ í•™ìŠµ\n",
        "# num_words 12000, batch_size=256\n",
        "#embedding_size = 256\n",
        "#hidden_size = 1024\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(enc_train, dec_train,epochs=10, batch_size=256, validation_data=(enc_val, dec_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QcFclABTihn",
        "outputId": "78712776-b6de-4be4-e38a-5f802820badc"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "501/501 [==============================] - 100s 193ms/step - loss: 3.5468 - val_loss: 3.1800\n",
            "Epoch 2/10\n",
            "501/501 [==============================] - 97s 194ms/step - loss: 3.0625 - val_loss: 2.9899\n",
            "Epoch 3/10\n",
            "501/501 [==============================] - 99s 197ms/step - loss: 2.8831 - val_loss: 2.8722\n",
            "Epoch 4/10\n",
            "501/501 [==============================] - 99s 197ms/step - loss: 2.7470 - val_loss: 2.7837\n",
            "Epoch 5/10\n",
            "501/501 [==============================] - 99s 197ms/step - loss: 2.6317 - val_loss: 2.7185\n",
            "Epoch 6/10\n",
            "501/501 [==============================] - 97s 194ms/step - loss: 2.5242 - val_loss: 2.6629\n",
            "Epoch 7/10\n",
            "501/501 [==============================] - 99s 198ms/step - loss: 2.4239 - val_loss: 2.6156\n",
            "Epoch 8/10\n",
            "501/501 [==============================] - 98s 195ms/step - loss: 2.3296 - val_loss: 2.5795\n",
            "Epoch 9/10\n",
            "501/501 [==============================] - 97s 195ms/step - loss: 2.2406 - val_loss: 2.5417\n",
            "Epoch 10/10\n",
            "501/501 [==============================] - 97s 194ms/step - loss: 2.1557 - val_loss: 2.5123\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff47a398ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì„¸ ë²ˆì§¸ ì‹œë„í•œ ëª¨ë¸ í•™ìŠµ\n",
        "# num_words 12000, batch_size=128\n",
        "#embedding_size = 256\n",
        "#hidden_size = 1024\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(enc_train, dec_train,epochs=10, batch_size=128, validation_data=(enc_val, dec_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9BNkXpzbIVf",
        "outputId": "d11df73b-c2e3-451c-a1cf-8f54a4fc03da"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1002/1002 [==============================] - 109s 106ms/step - loss: 3.4206 - val_loss: 3.1017\n",
            "Epoch 2/10\n",
            "1002/1002 [==============================] - 106s 106ms/step - loss: 2.9791 - val_loss: 2.9133\n",
            "Epoch 3/10\n",
            "1002/1002 [==============================] - 107s 106ms/step - loss: 2.7883 - val_loss: 2.7936\n",
            "Epoch 4/10\n",
            "1002/1002 [==============================] - 107s 107ms/step - loss: 2.6361 - val_loss: 2.7075\n",
            "Epoch 5/10\n",
            "1002/1002 [==============================] - 105s 105ms/step - loss: 2.4985 - val_loss: 2.6401\n",
            "Epoch 6/10\n",
            "1002/1002 [==============================] - 105s 105ms/step - loss: 2.3700 - val_loss: 2.5883\n",
            "Epoch 7/10\n",
            "1002/1002 [==============================] - 107s 107ms/step - loss: 2.2486 - val_loss: 2.5471\n",
            "Epoch 8/10\n",
            "1002/1002 [==============================] - 106s 106ms/step - loss: 2.1351 - val_loss: 2.5155\n",
            "Epoch 9/10\n",
            "1002/1002 [==============================] - 106s 106ms/step - loss: 2.0282 - val_loss: 2.4908\n",
            "Epoch 10/10\n",
            "1002/1002 [==============================] - 107s 107ms/step - loss: 1.9282 - val_loss: 2.4774\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3f7d8ff50>"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë„¤ ë²ˆì§¸ ì‹œë„í•œ ëª¨ë¸ í•™ìŠµ\n",
        "# num_words 15000, batch_size=128\n",
        "#embedding_size = 256\n",
        "#hidden_size = 1024\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(enc_train, dec_train,epochs=10, batch_size=128, validation_data=(enc_val, dec_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYCiNjZEmHzw",
        "outputId": "a9982873-8485-424a-b650-02cf849c96e9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1002/1002 [==============================] - 117s 114ms/step - loss: 3.4107 - val_loss: 3.1122\n",
            "Epoch 2/10\n",
            "1002/1002 [==============================] - 123s 123ms/step - loss: 2.9958 - val_loss: 2.9346\n",
            "Epoch 3/10\n",
            "1002/1002 [==============================] - 114s 114ms/step - loss: 2.8168 - val_loss: 2.8257\n",
            "Epoch 4/10\n",
            "1002/1002 [==============================] - 113s 112ms/step - loss: 2.6769 - val_loss: 2.7475\n",
            "Epoch 5/10\n",
            "1002/1002 [==============================] - 112s 112ms/step - loss: 2.5519 - val_loss: 2.6865\n",
            "Epoch 6/10\n",
            "1002/1002 [==============================] - 113s 113ms/step - loss: 2.4359 - val_loss: 2.6382\n",
            "Epoch 7/10\n",
            "1002/1002 [==============================] - 123s 123ms/step - loss: 2.3278 - val_loss: 2.6004\n",
            "Epoch 8/10\n",
            "1002/1002 [==============================] - 124s 124ms/step - loss: 2.2279 - val_loss: 2.5712\n",
            "Epoch 9/10\n",
            "1002/1002 [==============================] - 124s 124ms/step - loss: 2.1346 - val_loss: 2.5506\n",
            "Epoch 10/10\n",
            "1002/1002 [==============================] - 114s 114ms/step - loss: 2.0468 - val_loss: 2.5373\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3f64db4d0>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ë‹¤ì„¯ ë²ˆì§¸ ì‹œë„í•œ ëª¨ë¸ í•™ìŠµ\n",
        "# num_words 12000, batch_size=128\n",
        "# ì˜µí‹°ë§ˆì´ì € ìˆ˜ì •\n",
        "#embedding_size = 128\n",
        "#hidden_size = 1024\n",
        "\n",
        "optimizer = tf.keras.optimizers.SGD()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(enc_train, dec_train, epochs=10, batch_size=128, validation_data=(enc_val, dec_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRxr_hw3p1ZZ",
        "outputId": "c2636542-5009-421d-a797-cd6d5595aea2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1002/1002 [==============================] - 94s 90ms/step - loss: 85.3905 - val_loss: 60.1697\n",
            "Epoch 2/10\n",
            "1002/1002 [==============================] - 92s 91ms/step - loss: 52.2011 - val_loss: 45.1717\n",
            "Epoch 3/10\n",
            "1002/1002 [==============================] - 90s 90ms/step - loss: 47.8096 - val_loss: 42.3885\n",
            "Epoch 4/10\n",
            "1002/1002 [==============================] - 92s 91ms/step - loss: 44.4562 - val_loss: 55.8165\n",
            "Epoch 5/10\n",
            "1002/1002 [==============================] - 90s 90ms/step - loss: 48.0046 - val_loss: 32.7403\n",
            "Epoch 6/10\n",
            "1002/1002 [==============================] - 92s 91ms/step - loss: 55.3751 - val_loss: 52.3362\n",
            "Epoch 7/10\n",
            "1002/1002 [==============================] - 90s 90ms/step - loss: 52.6024 - val_loss: 67.0664\n",
            "Epoch 8/10\n",
            "1002/1002 [==============================] - 90s 90ms/step - loss: 53.5306 - val_loss: 54.2085\n",
            "Epoch 9/10\n",
            "1002/1002 [==============================] - 90s 90ms/step - loss: 51.0313 - val_loss: 31.8335\n",
            "Epoch 10/10\n",
            "1002/1002 [==============================] - 90s 90ms/step - loss: 51.4197 - val_loss: 53.0465\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3e80dbad0>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì—¬ì„¯ ë²ˆì§¸ ì‹œë„í•œ ëª¨ë¸ í•™ìŠµ\n",
        "# num_words 12000, batch_size=128\n",
        "# embedding_size = 512\n",
        "#hidden_size = 1024\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(enc_train, dec_train,epochs=10, batch_size=128, validation_data=(enc_val, dec_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhVuUuDswqal",
        "outputId": "122703e6-1f6f-4804-c6a4-fcf3c9d8fbf3"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1002/1002 [==============================] - 115s 112ms/step - loss: 3.3277 - val_loss: 3.0330\n",
            "Epoch 2/10\n",
            "1002/1002 [==============================] - 112s 112ms/step - loss: 2.9015 - val_loss: 2.8401\n",
            "Epoch 3/10\n",
            "1002/1002 [==============================] - 112s 112ms/step - loss: 2.7029 - val_loss: 2.7215\n",
            "Epoch 4/10\n",
            "1002/1002 [==============================] - 112s 112ms/step - loss: 2.5397 - val_loss: 2.6364\n",
            "Epoch 5/10\n",
            "1002/1002 [==============================] - 112s 112ms/step - loss: 2.3929 - val_loss: 2.5717\n",
            "Epoch 6/10\n",
            "1002/1002 [==============================] - 112s 112ms/step - loss: 2.2566 - val_loss: 2.5195\n",
            "Epoch 7/10\n",
            "1002/1002 [==============================] - 112s 112ms/step - loss: 2.1298 - val_loss: 2.4821\n",
            "Epoch 8/10\n",
            "1002/1002 [==============================] - 112s 112ms/step - loss: 2.0117 - val_loss: 2.4535\n",
            "Epoch 9/10\n",
            "1002/1002 [==============================] - 112s 112ms/step - loss: 1.9011 - val_loss: 2.4292\n",
            "Epoch 10/10\n",
            "1002/1002 [==============================] - 112s 112ms/step - loss: 1.7974 - val_loss: 2.4164\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3951e0a50>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì¼ê³± ë²ˆì§¸ ì‹œë„í•œ ëª¨ë¸ í•™ìŠµ\n",
        "# num_words 12000, batch_size=128\n",
        "# embedding_size = 1024\n",
        "#hidden_size = 1024\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(enc_train, dec_train,epochs=15, batch_size=128, validation_data=(enc_val, dec_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpiFKp5-4EBJ",
        "outputId": "215862a2-59f2-4f7f-812d-ceeea7814047"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "1002/1002 [==============================] - 130s 128ms/step - loss: 3.2690 - val_loss: 2.9727\n",
            "Epoch 2/15\n",
            "1002/1002 [==============================] - 118s 118ms/step - loss: 2.8378 - val_loss: 2.7813\n",
            "Epoch 3/15\n",
            "1002/1002 [==============================] - 118s 118ms/step - loss: 2.6278 - val_loss: 2.6580\n",
            "Epoch 4/15\n",
            "1002/1002 [==============================] - 118s 118ms/step - loss: 2.4426 - val_loss: 2.5676\n",
            "Epoch 5/15\n",
            "1002/1002 [==============================] - 118s 118ms/step - loss: 2.2695 - val_loss: 2.4959\n",
            "Epoch 6/15\n",
            "1002/1002 [==============================] - 119s 119ms/step - loss: 2.1058 - val_loss: 2.4366\n",
            "Epoch 7/15\n",
            "1002/1002 [==============================] - 119s 118ms/step - loss: 1.9511 - val_loss: 2.3969\n",
            "Epoch 8/15\n",
            "1002/1002 [==============================] - 119s 119ms/step - loss: 1.8084 - val_loss: 2.3710\n",
            "Epoch 9/15\n",
            "1002/1002 [==============================] - 119s 119ms/step - loss: 1.6771 - val_loss: 2.3524\n",
            "Epoch 10/15\n",
            "1002/1002 [==============================] - 119s 119ms/step - loss: 1.5589 - val_loss: 2.3469\n",
            "Epoch 11/15\n",
            "1002/1002 [==============================] - 119s 119ms/step - loss: 1.4523 - val_loss: 2.3553\n",
            "Epoch 12/15\n",
            "1002/1002 [==============================] - 129s 129ms/step - loss: 1.3577 - val_loss: 2.3631\n",
            "Epoch 13/15\n",
            "1002/1002 [==============================] - 119s 119ms/step - loss: 1.2755 - val_loss: 2.3830\n",
            "Epoch 14/15\n",
            "1002/1002 [==============================] - 118s 118ms/step - loss: 1.2042 - val_loss: 2.4013\n",
            "Epoch 15/15\n",
            "1002/1002 [==============================] - 118s 117ms/step - loss: 1.1434 - val_loss: 2.4210\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3e98859d0>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ì—¬ëŸ ë²ˆì§¸ ì‹œë„í•œ ëª¨ë¸ í•™ìŠµ\n",
        "# num_words 12000, batch_size=64\n",
        "# embedding_size = 1024\n",
        "#hidden_size = 1024\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "model.compile(loss=loss, optimizer=optimizer)\n",
        "model.fit(enc_train, dec_train,epochs=10, batch_size=64, validation_data=(enc_val, dec_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQM6AVDLAOFi",
        "outputId": "5e7eb468-a472-42dd-a169-f1f3e8e94dad"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2004/2004 [==============================] - 135s 66ms/step - loss: 3.1336 - val_loss: 2.8551\n",
            "Epoch 2/10\n",
            "2004/2004 [==============================] - 132s 66ms/step - loss: 2.6900 - val_loss: 2.6507\n",
            "Epoch 3/10\n",
            "2004/2004 [==============================] - 132s 66ms/step - loss: 2.4159 - val_loss: 2.5147\n",
            "Epoch 4/10\n",
            "2004/2004 [==============================] - 132s 66ms/step - loss: 2.1670 - val_loss: 2.4227\n",
            "Epoch 5/10\n",
            "2004/2004 [==============================] - 132s 66ms/step - loss: 1.9406 - val_loss: 2.3612\n",
            "Epoch 6/10\n",
            "2004/2004 [==============================] - 132s 66ms/step - loss: 1.7386 - val_loss: 2.3271\n",
            "Epoch 7/10\n",
            "2004/2004 [==============================] - 132s 66ms/step - loss: 1.5664 - val_loss: 2.3178\n",
            "Epoch 8/10\n",
            "2004/2004 [==============================] - 132s 66ms/step - loss: 1.4221 - val_loss: 2.3198\n",
            "Epoch 9/10\n",
            "2004/2004 [==============================] - 132s 66ms/step - loss: 1.3040 - val_loss: 2.3369\n",
            "Epoch 10/10\n",
            "2004/2004 [==============================] - 132s 66ms/step - loss: 1.2091 - val_loss: 2.3670\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff3f9399a90>"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "â— ë°¸ë¦¬ë°ì´ì…˜ ë¡œìŠ¤ë¥¼ ì¤„ì´ê¸° ìœ„í•œ ë…¸ë ¥ì€ ì•„ë˜ íšŒê³ ì—ì„œ ë‹¤ë£¨ê² ë‹¤."
      ],
      "metadata": {
        "id": "bjB3Omzh2I7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "â— ë°¸ë¦¬ë°ì´ì…˜ ë¡œìŠ¤   \n",
        "1) ë°¸ë¦¬ë°ì´ì…˜ ë¡œìŠ¤ë€?  \n",
        "overfittingì„ í•´ê²°í•˜ê¸° ìœ„í•´ ë³„ë¡œë„ ë§Œë“¤ì–´ì§„ datasetì´ ì•„ë‹ˆë¼, training datasetì—ì„œ ì¶”ì¶œëœ ê°€ìƒì˜ datasetì„.\n",
        "\n",
        "2) ë§Œì•½ ë°¸ë¦¬ë°ì´ì…˜ ë¡œìŠ¤ê°€ ì•ˆ ì¤„ì–´ë“¤ ë•?   \n",
        "- ë°ì´í„° ì „ì²˜ë¦¬ : ë°ì´í„° í‘œì¤€í™” ë° ì •ê·œí™”(ë°°ì¹˜ë†ˆ, ìŠ¤ì¼€ì¼ë§)   \n",
        "- ëª¨ë¸ ê°•ì œì„± : ëª¨ë¸ì´ ë„ˆë¬´ ë³µì¡í•˜ì§€ ì•Šì€ì§€ í™•ì¸, dropoutì„ ì¶”ê°€í•˜ê³  ê° ê³„ì¸µì˜ ë ˆì´ì–´ ìˆ˜ ë˜ëŠ” ë‰´ëŸ° ìˆ˜ ì¤„ì´ê¸°   \n",
        "- í•™ìŠµ ì†ë„ ë° ê°ì†Œ ì†ë„ : í•™ìŠµ ì†ë„ ì¤„ì´ê¸°\n",
        "\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbhzwwY%2FbtqAtbHdeNA%2FpRBnbKySV9asFqpI1Ozc71%2Fimg.png\" width=\"\" height=\"\"  title=\"px(í”½ì…€) í¬ê¸° ì„¤ì •\" alt=\"ë°¸ë¦¬ë°ì´ì…˜ë°ì´í„°ì…‹\"></img><br/>\n",
        "[ë°¸ë¦¬ë°ì´ì…˜ ë°ì´í„°ì…‹ì„ ì´ìš©í•œ í•™ìŠµ ê³¼ì •]\n",
        "ë§Œì•½ ë°¸ë¦¬ë°ì´ì…˜ ë¡œìŠ¤ê°€ ì¦ê°€í–ˆë‹¤ë©´ í•™ìŠµì„ ì¢…ë£Œí•œë‹¤.   \n",
        "ê·¸ë ‡ì§€ ì•Šì„ ê²½ìš°ëŠ” (2)ë¡œ ëŒì•„ê°€ í•™ìŠµì„ ê³„ì† ì§„í–‰í•¨   \n",
        "\n",
        "(3)(4)ê³¼ì •ì„ í†µí•´ í˜„ì¬ ëª¨ë¸ì´ í•™ìŠµ ê³¼ì •ì—ì„œ ì°¸ì¡°í•˜ì§€ ì•Šì•˜ë˜ dataë¥¼ ì–¼ë§ˆë‚˜ ì •í™•í•˜ê²Œ ì˜ˆì¸¡í•˜ëŠ”ì§€ í‰ê°€í•˜ê³ , ì´ë¥¼ í•™ìŠµì˜ ì¢…ë£Œ ì¡°ê±´ìœ¼ë¡œ ì´ìš©í•¨ìœ¼ë¡œì¨ overfittingì„ ê°„ì ‘ì ìœ¼ë¡œ ë°©ì§€\n",
        "<img src=\"https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fb7W55F%2FbtqAtCq1C4B%2FifxO1FuK1p0b3LuzvJKbOk%2Fimg.png\" width=\"\" height=\"\"  title=\"px(í”½ì…€) í¬ê¸° ì„¤ì •\" alt=\"ë°¸ë¦¬ë°ì´ì…˜ë¡œìŠ¤\"></img><br/>\n",
        "validation lossê°€ ì¦ê°€í•˜ëŠ” ì‹œì ë¶€í„° overfittingì´ ë°œìƒí–ˆë‹¤ê³  íŒë‹¨í•˜ê³ , ì´ì— ë”°ë¼ í•™ìŠµì„ ì¤‘ë‹¨í•œë‹¤.   \n",
        " validation dataset ë˜í•œ test datasetì„ ì™„ë²½íˆ í‘œí˜„í•˜ì§€ëŠ” ëª» í•˜ê¸° ë•Œë¬¸ì— validation lossê°€ ìµœì†Œê°€ ë˜ëŠ” ì‹œì ì´ test lossê°€ ìµœì†Œê°€ ë˜ëŠ” ì‹œì ê³¼ ì •í™•íˆ ì¼ì¹˜í•˜ì§€ëŠ” ì•Šì„ ìˆ˜ë„ ìˆë‹¤."
      ],
      "metadata": {
        "id": "GDmG5fnq2SXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step 6. ì‘ë¬¸ í‰ê°€ "
      ],
      "metadata": {
        "id": "i_QuMK1sfDsF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
        "    # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ì„œ ì…ë ¥ë°›ì€ init_sentenceë„ í…ì„œë¡œ ë³€í™˜í•©ë‹ˆë‹¤\n",
        "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
        "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
        "    end_token = tokenizer.word_index[\"<end>\"]\n",
        "\n",
        "    # ë‹¨ì–´ í•˜ë‚˜ì”© ì˜ˆì¸¡í•´ ë¬¸ì¥ì„ ë§Œë“­ë‹ˆë‹¤\n",
        "    #    1. ì…ë ¥ë°›ì€ ë¬¸ì¥ì˜ í…ì„œë¥¼ ì…ë ¥í•©ë‹ˆë‹¤\n",
        "    #    2. ì˜ˆì¸¡ëœ ê°’ ì¤‘ ê°€ì¥ ë†’ì€ í™•ë¥ ì¸ word indexë¥¼ ë½‘ì•„ëƒ…ë‹ˆë‹¤\n",
        "    #    3. 2ì—ì„œ ì˜ˆì¸¡ëœ word indexë¥¼ ë¬¸ì¥ ë’¤ì— ë¶™ì…ë‹ˆë‹¤\n",
        "    #    4. ëª¨ë¸ì´ <end>ë¥¼ ì˜ˆì¸¡í–ˆê±°ë‚˜, max_lenì— ë„ë‹¬í–ˆë‹¤ë©´ ë¬¸ì¥ ìƒì„±ì„ ë§ˆì¹©ë‹ˆë‹¤\n",
        "    while True:\n",
        "        # 1\n",
        "        predict = model(test_tensor) \n",
        "        # 2\n",
        "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
        "        # 3 \n",
        "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
        "        # 4\n",
        "        if predict_word.numpy()[0] == end_token: break\n",
        "        if test_tensor.shape[1] >= max_len: break\n",
        "\n",
        "    generated = \"\"\n",
        "    # tokenizerë¥¼ ì´ìš©í•´ word indexë¥¼ ë‹¨ì–´ë¡œ í•˜ë‚˜ì”© ë³€í™˜í•©ë‹ˆë‹¤ \n",
        "    for word_index in test_tensor[0].numpy():\n",
        "        generated += tokenizer.index_word[word_index] + \" \"\n",
        "\n",
        "    return generated\n",
        "\n",
        "generate_text(model, tokenizer, init_sentence=\"<start> i love\", max_len=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GIFD4zywqRlN",
        "outputId": "569c26ec-5bbd-4efd-de50-3e202e76e0dd"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start> i love you <end> '"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ì´ëŠ” ëª¨ë¸ í•™ìŠµ ì‹¤í—˜ ê³¼ì • ì¤‘ì— ë°›ì•„ë‚¸ ê²°ê³¼ê°’ì´ë‹¤.   \n",
        "ì œì¼ ì²˜ìŒ ë°›ì•˜ë˜ ë¬¸ì¥ì€ ë‹¤ì†Œ ê´´ìƒí–ˆë‹¤(?) ì•„ë¬´ìƒê°ì—†ì´ ì§€ì›Œë²„ë ¤ ê¸°ë¡ì´ ì—†ì§€ë§Œ..ã… ã… \n",
        "ê·¸ë˜ì„œ ìš°ì„  ìµœì¢… ëª¨ë¸ í•™ìŠµ ê²°ê³¼ì™€ ë¹„êµë¥¼ í•˜ê¸° ìœ„í•´ ë‚¨ê²¨ë‘ì—ˆë‹¤.   \n",
        "validation loss ê·¼ë°©ì—ì„œëŠ” ë¬¸ì¥ì´ ìœ„ì™€ ë™ì¼í•˜ê²Œ ì¶œë ¥ë˜ì—ˆë‹¤."
      ],
      "metadata": {
        "id": "kcATlC-3gFIU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "keywords = ['I love', 'you are', 'love', 'I', 'she', 'he', 'If']\n",
        "for start in keywords:\n",
        "    print(generate_text(model, tokenizer, init_sentence= ' '.join([\"<start>\", start])))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8i3cvgH4f48G",
        "outputId": "81ea63d0-f9df-4e68-83c3-1cf795f207d6"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<start> i love you , i love you <end> \n",
            "<start> you are gonna have to find out for yourself <end> \n",
            "<start> love is a beautiful thing <end> \n",
            "<start> i m gonna make contact tonight . <end> \n",
            "<start> she s got that vibe <end> \n",
            "<start> he s a monster <end> \n",
            "<start> if you want me <end> \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " ë§ˆì§€ë§‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ í›„ ì¶œë ¥í•´ë³´ì•˜ë‹¤.   \n",
        " I loveì— ëŒ€í•´ì„œëŠ” 'i love you , i love you' ê°€ ì¶œë ¥ë˜ì—ˆë‹¤.   \n",
        " ê·¸ ì™¸ ë‹¤ë¥¸ í‚¤ì›Œë“œë„ ì œì‹œí•´ë³´ì•˜ë‹¤. ê½¤ë‚˜ ì™„ì„±ë„ ë†’ì€ ë¬¸ì¥ë“¤ì´ ì¶œë ¥ë˜ì—ˆë‹¤.   \n",
        "ì´ ì •ë„ ê²°ê³¼ë¬¼ì´ë©´ í›Œë¥­í•˜ë‹¤ê³  ìƒê°í•˜ê¸°ì—, ë‚˜ëŠ” ë§¤ìš° ë§Œì¡±í•œë‹¤."
      ],
      "metadata": {
        "id": "_gqW40oPg5vW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dF0nBe234Co"
      },
      "source": [
        "#Step 7. íšŒê³ \n",
        "<ì •ì œí•¨ìˆ˜ í™œìš© ë°ì´í„° êµ¬ì¶•>\n",
        "\n",
        "í† í°ì˜ ê°œìˆ˜ê°€ 15ê°œë¥¼ ë„˜ì–´ê°€ëŠ” ë¬¸ì¥ì„ í•™ìŠµ ë°ì´í„°ì—ì„œ ì œì™¸ ì½”ë“œë¥¼ ì§œì¤„ ë•Œ ì—¬ëŸ¬ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆë‹¤\n",
        "\n",
        "1. if len(sentence.count()) >15: continue\n",
        "\n",
        "  => TypeError: count() takes at least 1 argument (0 given)\n",
        "\n",
        "  ì¸ìˆ˜ê°€ í•„ìš”í•˜ë‹¤ê¸¸ë˜ count() ì•ˆì— corpus ë¥¼ ë„£ì–´ì£¼ì—ˆë‹¤.\n",
        "2. if len(sentence.count(corpus)) >15: continue\n",
        "\n",
        "  => TypeError: must be str, not list\n",
        "\n",
        "ì—¬ê¸°ì„œ ì•„ì§ë„ ê°œë…ì´ ì˜ ì¡íˆì§€ ì•Šì€ ê²ƒ ê°™ì•„ íŒŒì´ì¬ 'ì¸ìˆ˜'ê°€ ë¬´ì—‡ì¸ê°€? \n",
        "  => í•¨ìˆ˜ë¥¼ ì •ì˜í•  ë•Œ ë„£ëŠ” ê°’(ë³€ìˆ˜)ë¥¼ ë§¤ê°œë³€ìˆ˜ë¼ í•˜ê³ , í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ë•Œ ë„£ëŠ” ê°’ì„ ì¸ìˆ˜ë¼ í•œë‹¤.\n",
        "\n",
        "  ì—¬ê¸°ì„œ ê°ì´ ì¡í˜”ë‹¤. í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ë•Œ ë„£ëŠ” ê°’ì„ ì¸ìˆ˜ë¼ê³  í•˜ëŠ”ë° ê·¸ëŸ¼ í•´ë‹¹ ë¶€ë¶„ì€ preprocessed_sentenceê°€ ì¸ìˆ˜ì´ë‹ˆê¹Œ\n",
        "\n",
        "  3. if len(preprocessed_sentence.count( )) >15: continue\n",
        "  \n",
        "  ìœ¼ìŒ... ì´ê²ƒë„ í•´ê²°ì´ ì•ˆë˜ëŠ”ê±° ê°™ì€ë° count í•¨ìˆ˜ëŠ” ëª» ì“°ë‚˜..?\n",
        "\n",
        "\n",
        "4. from collections import Counter    #count ì‚¬ìš©ì„ ìœ„í•´ import í•˜ê¸°\n",
        "\n",
        "5. if Counter(sentence) >15: continue\n",
        "  => TypeError: '>' not supported between instances of 'Counter' and 'int'\n",
        "\n",
        "   ì„¸ìƒì— ë¶€ë“±í˜¸ë¥¼ ì§€ì›ì•ˆí•œë‹¤ë‹ˆã… ã… \n",
        "   <= ë˜ëŠ” >= ì´ë ‡ê²Œ ì‚¬ìš©í•´ì•„í•œë‹¤ê³  í•œë‹¤..\n",
        "\n",
        "   ** counter() ì™€ count()ì˜ ì°¨ì´\n",
        "\n",
        "###â—â—ë°¸ë¦¬ë°ì´ì…˜ ë¡œìŠ¤â—â—\n",
        "ì´ë²ˆ ëª¨ë¸ì—ì„œ í•µì‹¬ì€ ë°¸ë¦¬ë°ì´ì…˜ ë¡œìŠ¤ë¥¼ 2.2 ì´í•˜ë¡œ ì¤„ì´ëŠ” ê²ƒì´ë‹¤.   \n",
        "ì´ë¥¼ ì¤„ì´ê¸° ìœ„í•´ ìƒë‹¹íˆ ì• ì¼ëŠ”ë° í•œ ë²ˆ êµ¬í˜„í•  ë•Œë§ˆë‹¤ ì‹œê°„ì´ ìƒë‹¹íˆ ì˜¤ë˜ê±¸ë ¤ ì‰½ì§€ ì•Šì•˜ë‹¤.   \n",
        "ì²˜ìŒì— ê±´ë“œë¦°ê±´ ë°°ì¹˜ì‚¬ì´ì¦ˆì˜€ë‹¤.\n",
        "\n",
        "- â­ Batch sizeë€?   \n",
        "ì—°ì‚° í•œ ë²ˆ í• ë•Œ ë“¤ì–´ê°€ëŠ” ë°ì´í„°ì˜ í¬ê¸°ë¥¼ ë§í•¨.   \n",
        "ë°°ì¹˜ì‚¬ì´ì¦ˆê°€ í° ê²½ìš°(ìˆ«ìê°€ ì‘ì„ ê²½ìš°) í•œ ë²ˆì— ì²˜ë¦¬í•´ì•¼ í•  ë°ì´í„°ì˜ ì–‘ì´ ë§ì•„ì§€ê¸° ë•Œë¬¸ì— í•™ìŠµ ì†ë„ê°€ ëŠë ¤ì§.  \n",
        "ë°°ì¹˜ì‚¬ì´ì¦ˆê°€ ì‘ì„ ê²½ìš°(ìˆ«ìê°€ í¼) ì ì€ ë°ì´í„°ë¡œ ì—…ë°ì´íŠ¸ê°€ ìì£¼ ë°œìƒí•´ì„œ í›ˆë ¨ì´ ë¶ˆì•ˆì •í•¨  \n",
        "\n",
        "\n",
        "(1) ì²˜ìŒì—ëŠ” batch_size=512ë¡œ ì‹œì‘í•˜ì˜€ë‹¤. ì´ˆë°˜ë¶€í„° validation lossê°€ ê½¤ë‚˜ ì¢‹ê²Œ ë‚˜ì™€ ê¸°ëŒ€í–ˆì§€ë§Œ 2.5 ë¶€ê·¼ì—ì„œ ê³ ì „ì„ ë©´í•˜ì§€ ëª»í–ˆë‹¤. ê·¸ë˜ì„œ batch_size=256 ê·¸ë¦¬ê³  batch_size=128 ë¡œ ë³€ê²½í•˜ì—¬ ì§„í–‰í•´ë³´ì•˜ë‹¤. batch_size=256ë¡œ í•˜ì˜€ì„ ë•Œ validation lossê°’ì´ ì ì  ì¢‹ì•„ì§€ëŠ” ê²ƒì´ ëˆˆì— ë„ê²Œ ë³´ì˜€ë‹¤. í•˜ì§€ë§Œ ì—­ì‹œë‚˜ 2.5 ë¶€ê·¼ì—ì„œëŠ” validation lossì´ ê±°ì˜ ì œìë¦¬ ê±¸ìŒì´ì—ˆë‹¤. batch_size=128ë¡œ í•˜ì˜€ì„ ë• í•œ ë²ˆì— ì²˜ë¦¬í•´ì•¼í•  ë°ì´í„°ê°€ 1000ì´ìƒì´ ë˜ë©´ì„œ epoch í•œë²ˆ ë„ëŠ”ë° ìƒë‹¹í•œ ì‹œê°„ì´ ì†Œìš”ë˜ì—ˆë‹¤. í•˜ì§€ë§Œ 2.5ì´í•˜ì˜ ì˜ë¯¸ìˆëŠ” validation lossê°’ì„ ë°œê²¬í•˜ì˜€ê³ , batch_sizeëŠ” 128ë¡œ ê³ ì •ì‹œí‚¤ê³  ë‹¤ë¥¸ ìš”ì†Œë¥¼ ê±´ë“œë ¸ë‹¤. ì—¬ê¸°ì„œ ì²˜ìŒë¶€í„° epoch ìˆ˜ì¹˜ë¥¼ ê±´ë“¤ì§€ ì•Šì€ ì´ìœ ëŠ” epoch ë°˜ë³µí•  ë•Œë§ˆë‹¤ ë‚˜ì˜¤ëŠ” validation loss ìˆ˜ì¹˜ì—ì„œ ì˜ë¯¸ìˆëŠ” í•˜ë½í­ì´ ë‚˜ì˜¤ì§€ ì•Šìœ¼ë©´ ì•„ë¬´ë¦¬ epochë¥¼ ë†’ì—¬ë´¤ì ì›í•˜ëŠ” ìˆ˜ì¹˜ë¥¼ ì–»ê¸°ì—ëŠ” í˜ë“¤ ê²ƒì´ë¼ê³  íŒë‹¨í•˜ì˜€ê³ , ê³¼ì ‘í•© ë¬¸ì œë¥¼ ìƒê°í•´ì„œë¼ë„ ë§ˆì§€ë§‰ì— ìˆ˜ì •í•˜ëŠ” ê²ƒì´ ì¢‹ì„ ê²ƒì´ë¼ê³  ìƒê°í–ˆë‹¤.   \n",
        "(2) ë‘ ë²ˆì§¸ë¡œ ë§Œì§„ ê±´ num_words ì´ë‹¤. 12000 ì´ìƒìœ¼ë¡œ ì‚¬ìš©í•˜ë¼ëŠ” ê¸°ì¤€ì´ ìˆì—ˆê¸°ì— í˜¹ì‹œë‚˜ í•™ìŠµ ë°ì´í„°ê°€ ì‘ì•„ì„œ ìƒê¸´ ë¬¸ì œì§€ ì•Šì„ê¹Œ ì‹¶ì–´ 15000ìœ¼ë¡œ ëŠ˜ë ¤ í•™ìŠµì‹œì¼œë³´ì•˜ë‹¤. ë‹¨ì–´ì¥ ê°œìˆ˜ 15000ê°œê°€ 12000ê°œë³´ë‹¤ lossê°’ì´ ì•ˆ ì¢‹ì•„ 12000ê°œë¡œ ê³ ì •ì‹œì¼°ë‹¤.   \n",
        "(3) ì„¸ ë²ˆì§¸ë¡œëŠ” optimizerë¥¼ ìˆ˜ì •í•´ë³´ì•˜ë‹¤. Adam ì—ì„œ SGDë¡œ ë³€ê²½í•´ë³´ì•˜ëŠ”ë° lossê°’ì´ ê°‘ìê¸° ë‘ìë¦¿ìˆ˜ê°€ ë‚˜ì™€ ë‹¤ì‹œ Adamìœ¼ë¡œ ëŒë ¸ë‹¤...\n",
        "- ì˜µí‹°ë§ˆì´ì € Adam\n",
        "Adam ê¸°ë²•ì€ momentum ê¸°ë²•ê³¼ Rmsprop ê¸°ë²•ì„ í˜¼í•©í•œ ê¸°ë²•ìœ¼ë¡œ ì£¼ë¡œ ë‹¤ë¥¸ ì˜µí‹°ë§ˆì´ì €ì™€ ì„±ëŠ¥ë¹„êµë¥¼ í•´ë³´ë©´ ì†ì‹¤ê°’ì´ ê°€ì¥ ë§ì´ ë–¨ì–´ì§€ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n",
        "- ì˜µí‹°ë§ˆì´ì € SGD\n",
        "í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•ìœ¼ë¡œ, SGDëŠ” Adamê³¼ ë°˜ëŒ€ë¡œ ì„±ëŠ¥ì´ ê°€ì¥ ì¢‹ì§€ ì•Šì€ ê²½ìš°ë¥¼ ë§ì´ ë³´ì—¬ì¤€ë‹¤. SGDëŠ” ì†ì‹¤í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°ê°€ ë¬´ì‘ì • ë‚®ì•„ì§€ëŠ” ë°©í–¥ìœ¼ë¡œ ì§„í–‰ë˜ê¸° ë•Œë¬¸ì— ì†ì‹¤í•¨ìˆ˜ì˜ ê¸°ìš¸ê¸°ê°€ ìµœì €ê°’ì´ ë˜ëŠ” ê°’ì„ ì°¾ëŠ”ë° ë¹„íš¨ìœ¨ì ì¸ íƒìƒ‰ê²½ë¡œë¥¼ ì§€ë‹ˆê²Œ ëœë‹¤.\n",
        "\n",
        "(4) ë„¤ ë²ˆì§¸ë¡œ embedding_sizeë¥¼ ìˆ˜ì •í•¨. embedding_sizeê°€ ì»¤ì§ˆìˆ˜ë¡ Total params ê°€ ëŠ˜ì–´ë‚¬ê³ , ì´ëŠ” í•™ìŠµì— ê¸ì •ì ì¸ ì˜í–¥ì„ ë¼ì¹ ê²ƒì´ë¼ ìƒê°í–ˆë‹¤. ì‹¤ì œë¡œ embedding_sizeê°€ ì»¤ì§ˆìˆ˜ë¡ validation loss ê°’ì´ ë”ìš± ì¢‹ì•„ì§€ëŠ” ê²ƒì„ ë°œê²¬. validation loss = 128ì—ì„œ 256, 512, 1024ê¹Œì§€ ëŠ˜ë ¤ì„œ í•™ìŠµì„ ì‹œí‚´.   \n",
        "(5) ë‹¤ì„¯ ë²ˆì§¸ëŠ” epoch ë¥¼ 15ë¡œ ëŠ˜ë ¤ì„œ ì‹¤í—˜í•˜ì˜€ìœ¼ë‚˜ ì´ìƒí•˜ê²Œë„ validation lossê°€ ì ì  ë–¨ì–´ì§€ë”ë‹ˆ ë‹¤ì‹œ ì¦ê°€í•˜ì˜€ë‹¤. ë°”ë¡œ ì˜¤ë²„í”¼íŒ…ì´ì—ˆë˜ ê²ƒì´ë‹¤. ê·¸ë˜ì„œ epoch=10ì´ ê°€ì¥ ì ë‹¹í•œ í•™ìŠµíšŸìˆ˜ë¼ê³  íŒë‹¨í•˜ì˜€ë‹¤. ì´ì— batch_sizeì„ ì¬ìˆ˜ì •í•˜ê³  í•™ìŠµì„ ì‹œì¼œë³´ì•˜ë‹¤.   \n",
        "(6) ìœ„ ê³¼ì •ì„ ìˆ˜í–‰í•˜ì˜€ìŒì—ë„ ë¶ˆêµ¬í•˜ê³  validation lossê°€ 2.2 ì´í•˜ì— ë„ë‹¬í•˜ì§€ ëª»í•˜ì˜€ë‹¤. ë”°ë¼ì„œ hidden_sizeë¥¼ 2ë°°ë¡œ ì ìš©ì‹œì¼œì£¼ì—ˆë‹¤. ì´ë ‡ê²Œ ì„¤ì •í•´ì£¼ë‹ˆ epoch 6ì—ì„œë¶€í„° validation loss ê°€ ë‹¤ì‹œ ì»¤ì¡Œë‹¤. ì¦‰ ì˜¤ë²„í”¼íŒ…ì´ ì¼ì–´ë‚œ ê²ƒì´ë‹¤.   \n",
        "(7) ìµœì¢…ì ìœ¼ë¡œ epoch 5ë¡œ ì„¤ì •í•˜ì—¬  validation lossë¥¼ ì™„ë²½í•˜ê²Œ 2.2 ì´í•˜ë¡œ ë„ì¶œí•´ëƒˆë‹¤!!!!!!!!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 8. Reference\n",
        "1) https://untitledtblog.tistory.com/158   \n",
        "2) https://choosunsick.github.io/post/optimizer_compare/"
      ],
      "metadata": {
        "id": "ENfFr8Ni5MLB"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "[E-04]Make a Lyricsht.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmYFC1jp3vm6yC+cUf8lvg"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}