{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e74e60c",
   "metadata": {},
   "source": [
    "# 프로젝트: 뉴스기사 요약해보기\n",
    "\n",
    "## <목차>\n",
    "Step 1. 데이터 수집하기   \n",
    "Step 2. 데이터 전처리하기 (추상적 요약)   \n",
    "Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)   \n",
    "Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)   \n",
    "Step 5. Summa을 이용해서 추출적 요약해보기   \n",
    "🤔회고🤔\n",
    "\n",
    "# Step 1. 데이터 수집하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea747e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /aiffel/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패키지 준비 완료!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup \n",
    "from tensorflow.keras.preprocessing.text import Tokenizer \n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import urllib.request\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module='bs4')\n",
    "\n",
    "print('패키지 준비 완료!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3ccf857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98401\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>49952</th>\n",
       "      <td>14-year-old Navi Mumbai boy smashes 1,045 runs...</td>\n",
       "      <td>Tanishq Gavate, a 14-year-old Navi Mumbai stud...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73796</th>\n",
       "      <td>ISIS planned to blow up Aus plane using 'Barbi...</td>\n",
       "      <td>The Islamic State planned to blow up a plane i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86469</th>\n",
       "      <td>6 killed, 20 injured in two terrorist attacks ...</td>\n",
       "      <td>At least six people died and 20 injured after ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10267</th>\n",
       "      <td>Don't think users should focus on follower cou...</td>\n",
       "      <td>Talking about users' emphasis on the number of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88981</th>\n",
       "      <td>BJP's BP Mishra most active MP, has 100% atten...</td>\n",
       "      <td>BJP's Bhairon Prasad Mishra, who is a Lok Sabh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30014</th>\n",
       "      <td>Allahabad Mayor's car shows no number on licen...</td>\n",
       "      <td>Allahabad Mayor Abhilasha Gupta was seen trave...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13979</th>\n",
       "      <td>S Korea won't lift N Korea sanctions without U...</td>\n",
       "      <td>US President Donald Trump has said South Korea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60232</th>\n",
       "      <td>Western Railway launches online feedback syste...</td>\n",
       "      <td>Western Railway on Sunday launched an online f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26761</th>\n",
       "      <td>Diljit gifted former captain Sandeep Singh's h...</td>\n",
       "      <td>Actor Diljit Dosanjh was gifted former Indian ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40962</th>\n",
       "      <td>I-T Dept sends notice to company of Chanda Koc...</td>\n",
       "      <td>The Income Tax Department has sent a notice to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               headlines  \\\n",
       "49952  14-year-old Navi Mumbai boy smashes 1,045 runs...   \n",
       "73796  ISIS planned to blow up Aus plane using 'Barbi...   \n",
       "86469  6 killed, 20 injured in two terrorist attacks ...   \n",
       "10267  Don't think users should focus on follower cou...   \n",
       "88981  BJP's BP Mishra most active MP, has 100% atten...   \n",
       "30014  Allahabad Mayor's car shows no number on licen...   \n",
       "13979  S Korea won't lift N Korea sanctions without U...   \n",
       "60232  Western Railway launches online feedback syste...   \n",
       "26761  Diljit gifted former captain Sandeep Singh's h...   \n",
       "40962  I-T Dept sends notice to company of Chanda Koc...   \n",
       "\n",
       "                                                    text  \n",
       "49952  Tanishq Gavate, a 14-year-old Navi Mumbai stud...  \n",
       "73796  The Islamic State planned to blow up a plane i...  \n",
       "86469  At least six people died and 20 injured after ...  \n",
       "10267  Talking about users' emphasis on the number of...  \n",
       "88981  BJP's Bhairon Prasad Mishra, who is a Lok Sabh...  \n",
       "30014  Allahabad Mayor Abhilasha Gupta was seen trave...  \n",
       "13979  US President Donald Trump has said South Korea...  \n",
       "60232  Western Railway on Sunday launched an online f...  \n",
       "26761  Actor Diljit Dosanjh was gifted former Indian ...  \n",
       "40962  The Income Tax Department has sent a notice to...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/sunnysai12345/News_Summary/master/news_summary_more.csv\", filename=\"news_summary_more.csv\")\n",
    "data = pd.read_csv('news_summary_more.csv', encoding='iso-8859-1')\n",
    "\n",
    "print('전체 샘플수 :', (len(data)))\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f35e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f7003d5",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 전처리하기 (추상적 요약)\n",
    "## (1)중복 샘플과 NULL 값이 존재하는 샘플 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b0fdb39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text 열에서 중복을 배제한 유일한 샘플의 수 : 98360\n",
      "headlines 열에서 중복을 배제한 유일한 샘플의 수 : 98280\n"
     ]
    }
   ],
   "source": [
    "print('text 열에서 중복을 배제한 유일한 샘플의 수 :', data['text'].nunique())\n",
    "print('headlines 열에서 중복을 배제한 유일한 샘플의 수 :', data['headlines'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d1144a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 98360\n"
     ]
    }
   ],
   "source": [
    "# inplace=True 를 설정하면 DataFrame 타입 값을 return 하지 않고 data 내부를 직접적으로 바꿉니다\n",
    "data.drop_duplicates(subset = ['text'], inplace=True)\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae9a1fd",
   "metadata": {},
   "source": [
    "- 데이터프레임에 Null 값이 있는지 확인\n",
    "- Null 값이 없기 때문에 null 값 제거하지 않아도 됨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8315f92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headlines    0\n",
      "text         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033bc695",
   "metadata": {},
   "source": [
    "## (2)텍스트 정규화와 불용어 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "687a8c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정규화 사전의 수:  120\n"
     ]
    }
   ],
   "source": [
    "contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\",\n",
    "                           \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\",\n",
    "                           \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",\n",
    "                           \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\",\n",
    "                           \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n",
    "                           \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\",\n",
    "                           \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\",\n",
    "                           \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\",\n",
    "                           \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\",\n",
    "                           \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\",\n",
    "                           \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\",\n",
    "                           \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\",\n",
    "                           \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\",\n",
    "                           \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\",\n",
    "                           \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\",\n",
    "                           \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n",
    "                           \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n",
    "                           \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\",\n",
    "                           \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\",\n",
    "                           \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\",\n",
    "                           \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\n",
    "                           \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\",\n",
    "                           \"you're\": \"you are\", \"you've\": \"you have\"}\n",
    "\n",
    "print(\"정규화 사전의 수: \", len(contractions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86aee823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "불용어 개수 : 179\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print('불용어 개수 :', len(stopwords.words('english') ))\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14ea32c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전처리 완료!\n"
     ]
    }
   ],
   "source": [
    "# 데이터 전처리 함수\n",
    "def preprocess_sentence(sentence, remove_stopwords=True):\n",
    "    sentence = sentence.lower() # 텍스트 소문자화\n",
    "    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n",
    "    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 (...) 제거 Ex) my husband (and myself!) for => my husband for\n",
    "    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n",
    "    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n",
    "    sentence = re.sub(r\"'s\\b\",\"\", sentence) # 소유격 제거. Ex) roland's -> roland\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n",
    "    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n",
    "    \n",
    "    # 불용어 제거 (Text)\n",
    "    if remove_stopwords:\n",
    "        tokens = ' '.join(word for word in sentence.split() if not word in stopwords.words('english') if len(word) > 1)\n",
    "    # 불용어 미제거 (Summary)\n",
    "    else:\n",
    "        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n",
    "    return tokens\n",
    "print('전처리 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f75cc8b",
   "metadata": {},
   "source": [
    "## (3) 샘플의 최대 길이 정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17eb7404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텍스트의 최소 길이 : 1\n",
      "텍스트의 최대 길이 : 91\n",
      "텍스트의 평균 길이 : 58.23813542090281\n",
      "요약의 최소 길이 : 1\n",
      "요약의 최대 길이 : 18\n",
      "요약의 평균 길이 : 9.553660024400163\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZEAAAEWCAYAAACnlKo3AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAdc0lEQVR4nO3df7xVdZ3v8ddb/JFXUSCIQbCOP6hEJ0lR6WYzlomI3dDG/FEpqUmWjjo3G3HypllOeLta10wTk8Supc6oySiFjOOPcRIFFPnhjwsiXiFEFAXUSQU/94/1Pbnc7H1YZ3H23mdz3s/HYz322p/1XWt99uac82Gt9V3fpYjAzMysjK2anYCZmbUuFxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxKzJJN0n6Wtp/quSHswte03S7s3LzqxjLiJmVUhaKumzFbH3/IFvhIjYMSKWNHKfZp3hImJmZqW5iJiVIGkXSbdKWiXpWUln5ZYdKOkhSa9KWiHpSknb5pYfJukpSWskXQmog/2EpD3T/PWSfibpLknrJD0saY9c249KmiFptaSnJR2bWzZG0hNpveWSzu3yL8V6JBcRs06StBXwL8DjwGDgUOAcSYenJhuAvwP6A59Iy7+Z1u0P3AZckJY/A3yyE7s/Hvge0BdYDFyStrsDMAP4NfCB1O4qScPSetcBX4+I3sA+wL919nObVeMiYlbbb9PRxKuSXgWuSvEDgAERcXFEvJWuWVxL9oebiJgTETMjYn1ELAWuAf46rTsGWBgR/xwRbwM/AV7oRE63R8QjEbEeuBEYnuKfA5ZGxC/Tfh8DbgW+mJa/DQyTtFNEvBIRj3b2yzCrxkXErLajIqJP+0Q6mgA+BOxSUWD+ARgIIOnDku6U9IKktcA/kh11AOwCPN++g8hGQP3z+wLyBecNYMdcTgdV5PRl4C/S8r8hK2DPSbpf0ic6sU+zmrZudgJmLeh54NmIGFpj+dXAY8AJEbFO0jnAMWnZCmDX9oaSlH+/mTndHxGHVVsYEbOAsZK2Ac4Ebumi/VoP5yMRs857BFgn6TxJ20vqJWkfSQek5b2BtcBrkj4KfCO37l3A3pK+IGlr4CzePVrYHHcCH5Z0oqRt0nSApL0kbSvpy5J2TqfQ1gLvdME+zVxEzDorIjaQXYMYDjwLvAT8Atg5NTkX+BKwjuxayc25dV8iu04xEXgZGAr8RxfktA4YRXZd5o9kp70uBbZLTU4ElqbTa6eTneoy22zyQ6nMzKwsH4mYmVlpLiJmZlaai4iZmZXmImJmZqX1uPtE+vfvH21tbc1Ow8yspcyZM+eliBhQGe9xRaStrY3Zs2c3Ow0zs5Yi6blqcZ/OMjOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9J63B3rZvXUNuGumsuWTjyygZmYNYaPRMzMrDQXETMzK81FxMzMSvM1EbMW4est1h3V7UhE0q6S7pX0hKSFks5O8YskLZc0N01jcuucL2mxpKclHZ6Lj06xxZIm5OK7SXo4xW+WtG29Po+ZmW2snqez1gPfiohhwEjgDEnD0rIfR8TwNE0DSMuOB/YGRgNXSeolqRfwM+AIYBhwQm47l6Zt7Qm8Apxax89jZmYV6lZEImJFRDya5tcBTwKDO1hlLHBTRLwZEc8Ci4ED07Q4IpZExFvATcBYSQI+A/xzWn8KcFRdPoyZmVXVkAvrktqAjwMPp9CZkuZJmiypb4oNBp7PrbYsxWrF3w+8GhHrK+LV9j9e0mxJs1etWtUVH8nMzGhAEZG0I3ArcE5ErAWuBvYAhgMrgMvqnUNETIqIERExYsCAjR4RbGZmJdW1d5akbcgKyI0RcRtARKzMLb8WuDO9XQ7smlt9SIpRI/4y0EfS1uloJN/ezMwaoJ69swRcBzwZEZfn4oNyzY4GFqT5qcDxkraTtBswFHgEmAUMTT2xtiW7+D41IgK4FzgmrT8OuKNen8fMzDZWzyORTwInAvMlzU2xfyDrXTUcCGAp8HWAiFgo6RbgCbKeXWdExAYASWcC04FewOSIWJi2dx5wk6QfAI+RFS0zM2uQuhWRiHgQUJVF0zpY5xLgkirxadXWi4glZL23zMysCTzsiZmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmouImZmV5iJiZmaluYiYmVlpdSsiknaVdK+kJyQtlHR2iveTNEPSovTaN8Ul6QpJiyXNk7RfblvjUvtFksbl4vtLmp/WuUKS6vV5zMxsY/U8ElkPfCsihgEjgTMkDQMmAPdExFDgnvQe4AhgaJrGA1dDVnSAC4GDgAOBC9sLT2pzWm690XX8PGZmVqFuRSQiVkTEo2l+HfAkMBgYC0xJzaYAR6X5scANkZkJ9JE0CDgcmBERqyPiFWAGMDot2ykiZkZEADfktmVmZg3QkGsiktqAjwMPAwMjYkVa9AIwMM0PBp7PrbYsxTqKL6sSr7b/8ZJmS5q9atWqzfswZmb2Z3UvIpJ2BG4FzomItfll6Qgi6p1DREyKiBERMWLAgAH13p2ZWY9R1yIiaRuyAnJjRNyWwivTqSjS64spvhzYNbf6kBTrKD6kStzMzBqknr2zBFwHPBkRl+cWTQXae1iNA+7IxU9KvbRGAmvSaa/pwChJfdMF9VHA9LRsraSRaV8n5bZlZmYNsMkiIumLknqn+Qsk3ZbvftuBTwInAp+RNDdNY4CJwGGSFgGfTe8BpgFLgMXAtcA3ASJiNfB9YFaaLk4xUptfpHWeAX5XIC8zM+siWxdo8z8i4p8kHUz2R/9HZF1rD+popYh4EKh138ahVdoHcEaNbU0GJleJzwb26TB7MzOrmyKnszak1yOBSRFxF7Bt/VIyM7NWUaSILJd0DXAcME3SdgXXMzOzLVyRYnAs2cXtwyPiVaAf8O16JmVmZq1hk0UkIt4g64Z7cAqtBxbVMykzM2sNRXpnXQicB5yfQtsA/6eeSZmZWWsocjrraODzwOsAEfFHoHc9kzIzs9ZQpIi8lR+eRNIO9U3JzMxaRZEickvqndVH0mnAv5LdDGhmZj3cJm82jIj/JekwYC3wEeC7ETGj7pmZmVm3V+SOdVLRcOEwM7P3qFlEJK2j+jDtIhulZKe6ZWVmZi2hZhGJCPfAMjOzDhU6nZVG7T2Y7MjkwYh4rK5ZmZlZSyhys+F3yZ6F/n6gP3C9pAvqnZiZmXV/RY5EvgzsGxF/ApA0EZgL/KCOeZmZWQsocp/IH4H35d5vhx9Da2ZmFDsSWQMslDSD7JrIYcAjkq4AiIiz6pifmZl1Y0WKyO1pandffVIxM7NWU+SO9SmNSMTMzFpPkd5Zn5P0mKTVktZKWidpbSOSMzOz7q3I6ayfAF8A5qfRfM3MzIBivbOeBxa4gJiZWaUiRyJ/D0yTdD/wZnswIi6vW1ZmZtYSihSRS4DXyO4V2ba+6ZiZWSspUkR2iYh96p6JmZm1nCLXRKZJGlX3TMzMrOUUKSLfAH4v6T/dxdfMzPKK3Gzo54qYmVlVRZ8n0hcYSm4gxoh4oF5JmVnXaptwV4fLl048skGZ2JZmk0VE0teAs4EhZEPAjwQeAj5T18zMzKzbK3IkcjZwADAzIj4t6aPAP9Y3LbPm6eh/7f4fu9l7Fbmw/qfcA6m2i4ingI9saiVJkyW9KGlBLnaRpOWS5qZpTG7Z+ZIWS3pa0uG5+OgUWyxpQi6+m6SHU/xmSb6HxcyswYoUkWWS+gC/BWZIugN4rsB61wOjq8R/HBHD0zQNQNIw4Hhg77TOVZJ6SeoF/Aw4AhgGnJDaAlyatrUn8ApwaoGczMysCxXpnXV0mr1I0r3AzsDvC6z3gKS2gnmMBW6KiDeBZyUtBg5MyxZHxBIASTcBYyU9SXZN5kupzRTgIuDqgvszM7MuUGQo+D0kbdf+FmgD/stm7PNMSfPS6a6+KTaYbKDHdstSrFb8/cCrEbG+Il7rM4yXNFvS7FWrVm1G6mZmllfkdNatwAZJewKTgF2BX5fc39XAHsBwYAVwWcntdEpETIqIERExYsCAAY3YpZlZj1CkiLyT/sd/NPDTiPg2MKjMziJiZURsiIh3gGt595TVcrLi1G5IitWKvwz0kbR1RdzMzBqoSBF5W9IJwDjgzhTbpszOJOWLz9FAe8+tqcDxkraTtBvZjY2PALOAoakn1rZkF9+npmeb3Asck9YfB9xRJiczMyuvyH0iJwOnA5dExLPpj/yvNrWSpN8AhwD9JS0DLgQOkTQcCGAp8HWAiFgo6RbgCWA9cEZEbEjbOROYDvQCJkfEwrSL84CbJP0AeAy4rsgHNjOzrlOkd9YTwFm598+Sda/d1HonVAnX/EMfEZeQPbukMj4NmFYlvoR3T4eZmVkTFDmdZWZmVpWLiJmZlVaziEj6VXo9u3HpmJlZK+noSGR/SbsAp0jqK6lffmpUgmZm1n11dGH958A9wO7AHLK71dtFipuZWQ9W80gkIq6IiL3IutXuHhG75SYXEDMzK9TF9xuS9gU+lUIPRMS8+qZlZmatoMgAjGcBNwIfSNONkv623omZmVn3V+SO9a8BB0XE6wCSLiV7PO5P65mYmZl1f0XuExGwIfd+A++9yG5mZj1UkSORXwIPS7o9vT8Kj1NlZmYUu7B+uaT7gINT6OSIeKyuWZmZWUsociRCRDwKPFrnXMzMrMV47CwzMyvNRcTMzErrsIhI6iXp3kYlY2ZmraXDIpKeLviOpJ0blI+ZmbWQIhfWXwPmS5oBvN4ejIizaq9iZmY9QZEicluazMzM3qPIfSJTJG0PfDAinm5ATmZm1iKKDMD434C5wO/T++GSptY5LzMzawFFuvheBBwIvAoQEXPxA6nMzIxiReTtiFhTEXunHsmYmVlrKXJhfaGkLwG9JA0FzgL+UN+0zMysFRQ5EvlbYG/gTeA3wFrgnDrmZGZmLaJI76w3gO+kh1FFRKyrf1pmZtYKivTOOkDSfGAe2U2Hj0vav/6pmZlZd1fkmsh1wDcj4t8BJB1M9qCqj9UzMTMz6/6KXBPZ0F5AACLiQWB9/VIyM7NWUfNIRNJ+afZ+SdeQXVQP4DjgvvqnZmZm3V1HRyKXpWlf4MPAhWQ3Hu4FDN/UhiVNlvSipAW5WD9JMyQtSq99U1ySrpC0WNK8XAFD0rjUfpGkcbn4/pLmp3WukKTOfXQzM9tcNY9EIuLTm7nt64ErgRtysQnAPRExUdKE9P484AhgaJoOAq4GDpLUj6x4jSA7CpojaWpEvJLanAY8DEwDRgO/28yczcysEzZ5YV1SH+AkoC3fflNDwUfEA5LaKsJjgUPS/BSy02LnpfgNERHATEl9JA1KbWdExOqUywxgtKT7gJ0iYmaK3wAchYuImVlDFemdNQ2YCcxn84c7GRgRK9L8C8DAND8YeD7XblmKdRRfViVelaTxwHiAD37wg5uRvpmZ5RUpIu+LiP/e1TuOiJAUXb3dGvuaBEwCGDFiREP2aWbWExTp4vsrSadJGpQujPdL1yrKWJlOU5FeX0zx5cCuuXZDUqyj+JAqcTMza6AiReQt4EfAQ8CcNM0uub+pQHsPq3HAHbn4SamX1khgTTrtNR0YJalv6sk1Cpielq2VNDL1yjopty0zM2uQIqezvgXsGREvdWbDkn5DdmG8v6RlZL2sJgK3SDoVeA44NjWfBowBFgNvACcDRMRqSd8HZqV2F7dfZAe+SdYDbHuyC+q+qG5m1mBFikj7H/ZOiYgTaiw6tErbAM6osZ3JwOQq8dnAPp3Ny8zMuk6RIvI6MFfSvWTDwQOb7uJrZmZbviJF5LdpMjMze48izxOZ0ohEzMys9RS5Y/1ZsiFH3iMidq9LRmZm1jKKnM4akZt/H/BFoOx9ImZmtgXZ5H0iEfFybloeET8Bjqx/amZm1t0VOZ21X+7tVmRHJkWOYMzMbAtXpBhclptfDyzl3ZsEzcysByvSO2tznytiZmZbqCKns7YD/oaNnydycf3SMjOzVlDkdNYdwBqygRff3ERbMzPrQYoUkSERMbrumZiZWcspMhT8HyT9Zd0zMTOzllPkSORg4KvpzvU3AZENvPuxumZmZmbdXpEickTdszAzs5ZUpIvvc41IxMzMWk+RayJmZmZVuYiYmVlpLiJmZlaai4iZmZXmImJmZqW5iJiZWWkuImZmVpofLmVmHWqbcFeHy5dO9INOezIfiZiZWWkuImZmVpqLiJmZleYiYmZmpbmImJlZaS4iZmZWmrv42hbHXVLNGqcpRyKSlkqaL2mupNkp1k/SDEmL0mvfFJekKyQtljRP0n657YxL7RdJGteMz2Jm1pM183TWpyNieESMSO8nAPdExFDgnvQesicrDk3TeOBqyIoOcCFwEHAgcGF74TEzs8boTtdExgJT0vwU4Khc/IbIzAT6SBoEHA7MiIjVEfEKMAMY3eCczcx6tGYVkQDuljRH0vgUGxgRK9L8C8DAND8YeD637rIUqxXfiKTxkmZLmr1q1aqu+gxmZj1esy6sHxwRyyV9AJgh6an8wogISdFVO4uIScAkgBEjRnTZds3MerqmHIlExPL0+iJwO9k1jZXpNBXp9cXUfDmwa271ISlWK25mZg3S8CIiaQdJvdvngVHAAmAq0N7DahxwR5qfCpyUemmNBNak017TgVGS+qYL6qNSzMzMGqQZp7MGArdLat//ryPi95JmAbdIOhV4Djg2tZ8GjAEWA28AJwNExGpJ3wdmpXYXR8Tqxn0MMzNreBGJiCXAvlXiLwOHVokHcEaNbU0GJnd1jmZmVkx36uJrZmYtxkXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMysNBcRMzMrzUXEzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9Ia/ox1M7N2bRPu6nD50olHNigTK8tHImZmVpqLiJmZleYiYmZmpfmaiDVNR+fDfS7crDX4SMTMzEpzETEzs9JcRMzMrDQXETMzK81FxMzMSnMRMTOz0lxEzMystJa/T0TSaOB/A72AX0TExCanZGYN4HG3uoeWLiKSegE/Aw4DlgGzJE2NiCeam1nP4F9iM2vpIgIcCCyOiCUAkm4CxgIuImZWk/8D1HUUEc3OoTRJxwCjI+Jr6f2JwEERcWZFu/HA+PT2I8DTDU20nP7AS81OopNaLedWyxecc6O0Ws6NyPdDETGgMtjqRyKFRMQkYFKz8+gMSbMjYkSz8+iMVsu51fIF59worZZzM/Nt9d5Zy4Fdc++HpJiZmTVAqxeRWcBQSbtJ2hY4Hpja5JzMzHqMlj6dFRHrJZ0JTCfr4js5IhY2Oa2u0lKn35JWy7nV8gXn3CitlnPT8m3pC+tmZtZcrX46y8zMmshFxMzMSnMRaSJJu0q6V9ITkhZKOrtKm0MkrZE0N03fbUauuXyWSpqfcpldZbkkXSFpsaR5kvZrRp65fD6S++7mSlor6ZyKNk3/jiVNlvSipAW5WD9JMyQtSq99a6w7LrVZJGlck3P+kaSn0r/97ZL61Fi3w5+jBud8kaTluX//MTXWHS3p6fSzPaGJ+d6cy3WppLk11m3MdxwRnpo0AYOA/dJ8b+D/AsMq2hwC3NnsXHP5LAX6d7B8DPA7QMBI4OFm55zLrRfwAtlNU93qOwb+CtgPWJCL/U9gQpqfAFxaZb1+wJL02jfN921izqOArdP8pdVyLvJz1OCcLwLOLfCz8wywO7At8Hjl72qj8q1Yfhnw3WZ+xz4SaaKIWBERj6b5dcCTwODmZrXZxgI3RGYm0EfSoGYnlRwKPBMRzzU7kUoR8QCwuiI8FpiS5qcAR1VZ9XBgRkSsjohXgBnA6HrlmVct54i4OyLWp7czye7d6jZqfM9F/HmIpYh4C2gfYqmuOspXkoBjgd/UO4+OuIh0E5LagI8DD1dZ/AlJj0v6naS9G5vZRgK4W9KcNJxMpcHA87n3y+g+hfF4av/CdafvuN3AiFiR5l8ABlZp052/71PIjkqr2dTPUaOdmU7BTa5x2rA7fs+fAlZGxKIayxvyHbuIdAOSdgRuBc6JiLUVix8lO/2yL/BT4LcNTq/SwRGxH3AEcIakv2pyPoWkm1E/D/xTlcXd7TveSGTnJ1qmP76k7wDrgRtrNOlOP0dXA3sAw4EVZKeIWsEJdHwU0pDv2EWkySRtQ1ZAboyI2yqXR8TaiHgtzU8DtpHUv8Fp5vNZnl5fBG4nO8zP665D0RwBPBoRKysXdLfvOGdl+6nA9PpilTbd7vuW9FXgc8CXU/HbSIGfo4aJiJURsSEi3gGurZFLt/qeJW0NfAG4uVabRn3HLiJNlM5pXgc8GRGX12jzF6kdkg4k+zd7uXFZvieXHST1bp8nu4i6oKLZVOCk1EtrJLAmd0qmmWr+r607fccVpgLtva3GAXdUaTMdGCWpbzoNMyrFmkLZQ+L+Hvh8RLxRo02Rn6OGqbhmd3SNXLrbEEufBZ6KiGXVFjb0O673lXtPHfa8OJjsFMU8YG6axgCnA6enNmcCC8l6g8wE/msT89095fF4yuk7KZ7PV2QPCnsGmA+M6Abf8w5kRWHnXKxbfcdkBW4F8DbZ+fZTgfcD9wCLgH8F+qW2I8ie4tm+7inA4jSd3OScF5NdO2j/ef55arsLMK2jn6Mm5vyr9LM6j6wwDKrMOb0fQ9aD8plG5Vwt3xS/vv3nN9e2Kd+xhz0xM7PSfDrLzMxKcxExM7PSXETMzKw0FxEzMyvNRcTMzEpzEbEtlqTX6rDN4flRXtMIsOduxva+KOlJSfd2TYal81jaTW6wtBbjImLWOcPJ7hfoKqcCp0XEp7twm2YN4yJiPYKkb0ualQbZ+16KtaWjgGuVPc/lbknbp2UHpLZz0zMyFqQ7lS8Gjkvx49Lmh0m6T9ISSWfV2P8J6dkOCyRdmmLfJbvh9DpJP6poP0jSA2k/CyR9KsWvljQ75fu9XPulkn7Y/uwISftJmi7pGUmnpzaHpG3epey5GD+XtNHfAElfkfRI2tY1knql6fqUy3xJf7eZ/yS2pWjUnaKePDV6Al5Lr6OASWR3028F3En2nIY2skECh6d2twBfSfMLgE+k+Ymk5zkAXwWuzO3jIuAPwHZAf7I747epyGMX4P8BA4CtgX8DjkrL7qPKXf3At3h3RIBeQO803y8Xuw/4WHq/FPhGmv8x2d3XvdM+V6b4IcCfyO5m7kU2bPwxufX7A3sB/9L+GYCrgJOA/cmGnG/Pr0+z/309dY/JRyLWE4xK02NkI/Z+FBialj0bEXPT/BygTdnT+HpHxEMp/utNbP+uiHgzIl4iGySxcsj2A4D7ImJVZM/auJGsiHVkFnCypIuAv4zseTMAx0p6NH2WvYFhuXXax3KaT/YwsHURsQp4U+8+YfCRyJ6JsYFsSI2DK/Z7KFnBmKXsiXmHkhWdJcDukn6axseqHG3aeqitm52AWQMI+GFEXPOeYPYMlzdzoQ3A9iW2X7mNzf69iogH0tDdRwLXS7oc+HfgXOCAiHhF0vXA+6rk8U5FTu/kcqoc56jyvYApEXF+ZU6S9iV7CNbpZA9DOqWzn8u2PD4SsZ5gOnBKem4LkgZL+kCtxhHxKrBO0kEpdHxu8Tqy00Sd8Qjw15L6S+pFNqLw/R2tIOlDZKehrgV+QfaI1J2A14E1kgaSDW/fWQemkWi3Ao4DHqxYfg9wTPv3o+w57x9KPbe2iohbgQtSPmY+ErEtX0TcLWkv4KE04vtrwFfIjhpqORW4VtI7ZH/w16T4vcCEdKrnhwX3v0LShLSuyE5/VRvWPe8Q4NuS3k75nhQRz0p6DHiKbKTc/yiy/wqzgCuBPVM+t1fk+oSkC8ieiLcV2eixZwD/CfwydyF+oyMV65k8iq9ZFZJ2jPSgqlQABkXE2U1Oa7NIOgQ4NyI+1+RUbAviIxGz6o6UdD7Z78hzZL2yzKyCj0TMzKw0X1g3M7PSXETMzKw0FxEzMyvNRcTMzEpzETEzs9L+P0MyYp+/RdpGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 길이 분포 출력\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "text_len = [len(s.split()) for s in data['text']]\n",
    "headlines_len = [len(s.split()) for s in data['headlines']]\n",
    "\n",
    "print('텍스트의 최소 길이 : {}'.format(np.min(text_len)))\n",
    "print('텍스트의 최대 길이 : {}'.format(np.max(text_len)))\n",
    "print('텍스트의 평균 길이 : {}'.format(np.mean(text_len)))\n",
    "print('요약의 최소 길이 : {}'.format(np.min(headlines_len)))\n",
    "print('요약의 최대 길이 : {}'.format(np.max(headlines_len)))\n",
    "print('요약의 평균 길이 : {}'.format(np.mean(headlines_len)))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.boxplot(text_len)\n",
    "plt.title('Text')\n",
    "plt.subplot(1,2,2)\n",
    "plt.boxplot(headlines_len)\n",
    "plt.title('Headlines')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "plt.title('Text')\n",
    "plt.hist(text_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()\n",
    "\n",
    "plt.title('Headlines')\n",
    "plt.hist(headlines_len, bins = 40)\n",
    "plt.xlabel('length of samples')\n",
    "plt.ylabel('number of samples')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "237d1748",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "text_max_len = 62\n",
    "headlines_max_len = 13\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c48910d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "def below_threshold_len(max_len, nested_list):\n",
    "  cnt = 0\n",
    "  for s in nested_list:\n",
    "    if(len(s.split()) <= max_len):\n",
    "        cnt = cnt + 1\n",
    "  print('전체 샘플 중 길이가 %s 이하인 샘플의 비율: %s'%(max_len, (cnt / len(nested_list))))\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a6cf33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플 중 길이가 62 이하인 샘플의 비율: 0.9997153314355429\n",
      "전체 샘플 중 길이가 13 이하인 샘플의 비율: 0.9957706384709232\n"
     ]
    }
   ],
   "source": [
    "below_threshold_len(text_max_len, data['text'])\n",
    "below_threshold_len(headlines_max_len,  data['headlines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c6552c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 샘플수 : 97916\n"
     ]
    }
   ],
   "source": [
    "data = data[data['text'].apply(lambda x: len(x.split()) <= text_max_len)]\n",
    "data = data[data['headlines'].apply(lambda x: len(x.split()) <= headlines_max_len)]\n",
    "print('전체 샘플수 :', (len(data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc9f340",
   "metadata": {},
   "source": [
    "## (4) 시작 토큰과 종료 토큰 추가하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c482693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headlines</th>\n",
       "      <th>text</th>\n",
       "      <th>decoder_input</th>\n",
       "      <th>decoder_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "      <td>Saurav Kant, an alumnus of upGrad and IIIT-B's...</td>\n",
       "      <td>sostoken upGrad learner switches to career in ...</td>\n",
       "      <td>upGrad learner switches to career in ML &amp; Al w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "      <td>Kunal Shah's credit card bill payment platform...</td>\n",
       "      <td>sostoken Delhi techie wins free food from Swig...</td>\n",
       "      <td>Delhi techie wins free food from Swiggy for on...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "      <td>New Zealand defeated India by 8 wickets in the...</td>\n",
       "      <td>sostoken New Zealand end Rohit Sharma-led Indi...</td>\n",
       "      <td>New Zealand end Rohit Sharma-led India's 12-ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "      <td>With Aegon Life iTerm Insurance plan, customer...</td>\n",
       "      <td>sostoken Aegon life iTerm insurance plan helps...</td>\n",
       "      <td>Aegon life iTerm insurance plan helps customer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "      <td>Speaking about the sexual harassment allegatio...</td>\n",
       "      <td>sostoken Have known Hirani for yrs, what if Me...</td>\n",
       "      <td>Have known Hirani for yrs, what if MeToo claim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           headlines  \\\n",
       "0  upGrad learner switches to career in ML & Al w...   \n",
       "1  Delhi techie wins free food from Swiggy for on...   \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...   \n",
       "3  Aegon life iTerm insurance plan helps customer...   \n",
       "4  Have known Hirani for yrs, what if MeToo claim...   \n",
       "\n",
       "                                                text  \\\n",
       "0  Saurav Kant, an alumnus of upGrad and IIIT-B's...   \n",
       "1  Kunal Shah's credit card bill payment platform...   \n",
       "2  New Zealand defeated India by 8 wickets in the...   \n",
       "3  With Aegon Life iTerm Insurance plan, customer...   \n",
       "4  Speaking about the sexual harassment allegatio...   \n",
       "\n",
       "                                       decoder_input  \\\n",
       "0  sostoken upGrad learner switches to career in ...   \n",
       "1  sostoken Delhi techie wins free food from Swig...   \n",
       "2  sostoken New Zealand end Rohit Sharma-led Indi...   \n",
       "3  sostoken Aegon life iTerm insurance plan helps...   \n",
       "4  sostoken Have known Hirani for yrs, what if Me...   \n",
       "\n",
       "                                      decoder_target  \n",
       "0  upGrad learner switches to career in ML & Al w...  \n",
       "1  Delhi techie wins free food from Swiggy for on...  \n",
       "2  New Zealand end Rohit Sharma-led India's 12-ma...  \n",
       "3  Aegon life iTerm insurance plan helps customer...  \n",
       "4  Have known Hirani for yrs, what if MeToo claim...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 요약 데이터에는 시작 토큰과 종료 토큰을 추가한다.\n",
    "data['decoder_input'] = data['headlines'].apply(lambda x : 'sostoken '+ x)\n",
    "data['decoder_target'] = data['headlines'].apply(lambda x : x + ' eostoken')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90e45dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input = np.array(data['text']) # 인코더의 입력\n",
    "decoder_input = np.array(data['decoder_input']) # 디코더의 입력\n",
    "decoder_target = np.array(data['decoder_target']) # 디코더의 레이블\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e619a6f5",
   "metadata": {},
   "source": [
    " 훈련 데이터와 테스트 데이터를 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f43bc16a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55778 29421 36992 ... 79085  9880 87190]\n"
     ]
    }
   ],
   "source": [
    "indices = np.arange(encoder_input.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "print(indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3fc1b6",
   "metadata": {},
   "source": [
    "정수 시퀀스를 이용해 다시 데이터의 샘플 순서를 정의해 주면 잘 섞인 샘플이 되겠죠."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "661ceedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "encoder_input = encoder_input[indices]\n",
    "decoder_input = decoder_input[indices]\n",
    "decoder_target = decoder_target[indices]\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f34a91",
   "metadata": {},
   "source": [
    "섞인 데이터를 8:2의 비율로 훈련 데이터와 테스트 데이터로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0bcbb107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터의 수 : 19583\n"
     ]
    }
   ],
   "source": [
    "n_of_val = int(len(encoder_input)*0.2)\n",
    "print('테스트 데이터의 수 :', n_of_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf6c1538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 데이터의 개수 : 78333\n",
      "훈련 레이블의 개수 : 78333\n",
      "테스트 데이터의 개수 : 19583\n",
      "테스트 레이블의 개수 : 19583\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = encoder_input[:-n_of_val]\n",
    "decoder_input_train = decoder_input[:-n_of_val]\n",
    "decoder_target_train = decoder_target[:-n_of_val]\n",
    "\n",
    "encoder_input_test = encoder_input[-n_of_val:]\n",
    "decoder_input_test = decoder_input[-n_of_val:]\n",
    "decoder_target_test = decoder_target[-n_of_val:]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c519370",
   "metadata": {},
   "source": [
    "## (5) 단어 집합(vocabulary) 만들기 및 정수 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08b8d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tokenizer = Tokenizer() # 토크나이저 정의\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 입력된 데이터로부터 단어 집합 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22a52a76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 91273\n",
      "등장 빈도가 6번 이하인 희귀 단어의 수: 66532\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 24741\n",
      "단어 집합에서 희귀 단어의 비율: 72.89340768902085\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 2.743295961497961\n"
     ]
    }
   ],
   "source": [
    "threshold = 7\n",
    "total_cnt = len(src_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in src_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a981f97",
   "metadata": {},
   "source": [
    " 등장 빈도가 6회 이하인 단어들은 정수 인코딩 과정에서 빼고, 훈련 데이터에서 제거"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84daeb05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "src_vocab = 8000\n",
    "src_tokenizer = Tokenizer(num_words=src_vocab) # 단어 집합의 크기를 8,000으로 제한\n",
    "src_tokenizer.fit_on_texts(encoder_input_train) # 단어 집합 재생성\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0f03dfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 181, 28, 118, 638, 51, 75, 833, 2, 4497, 5, 1, 279, 214, 3516, 147, 12, 48, 1009, 6724, 15, 1, 1170, 4, 382, 1, 5280, 578, 962, 6, 208, 1304, 27, 379, 1742, 19, 1308, 1735, 28, 34, 111, 7994, 15, 18, 75, 2080, 4, 568, 6, 3805, 1520, 4, 1346, 9, 274], [3, 41, 2366, 1016, 7, 119, 1300, 11, 41, 59, 210, 137, 200, 38, 5281, 2657, 17, 2382, 7, 216, 90, 7, 45, 576, 3226, 5715, 205, 9, 45, 3226, 7, 267, 145, 4463, 684, 7652, 45, 445, 2, 486, 1389, 141, 1, 48, 4039, 5, 1, 2028, 1, 1016, 29, 711, 4650, 16, 1, 1937, 389], [1, 7293, 8, 174, 1, 31, 13, 174, 2, 1, 1969, 2859, 6, 3174, 4, 37, 252, 4563, 70, 9, 1, 48, 76, 1, 853, 12, 174, 4, 3, 724, 4563, 9, 24, 272, 490, 1, 7293, 8, 4, 1, 659, 4627, 2887, 2, 2859, 50, 20, 16]]\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train) \n",
    "encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n",
    "\n",
    "# 잘 진행되었는지 샘플 출력\n",
    "print(encoder_input_train[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3aea08b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=3\n"
     ]
    }
   ],
   "source": [
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2b520c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 40725\n",
      "등장 빈도가 5번 이하인 희귀 단어의 수: 29447\n",
      "단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 11278\n",
      "단어 집합에서 희귀 단어의 비율: 72.30693677102516\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 6.194631658244509\n"
     ]
    }
   ],
   "source": [
    "threshold = 6\n",
    "total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tar_tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :', total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'%(total_cnt - rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "89dafd35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input\n",
      "input  [[1, 1573, 7, 500, 346, 1977], [1, 39, 7, 159, 13, 469], [1, 743, 789, 4, 570, 5, 45, 59], [1, 404, 83, 3, 22, 4, 707, 30, 1840, 291, 1514], [1, 7, 159, 9]]\n",
      "target\n",
      "decoder  [[1573, 7, 500, 346, 1977, 2], [39, 7, 159, 13, 469, 2], [743, 789, 4, 570, 5, 45, 59, 2], [404, 83, 3, 22, 4, 707, 30, 1840, 291, 1514, 2], [7, 159, 9, 2]]\n"
     ]
    }
   ],
   "source": [
    "tar_vocab = 2000\n",
    "tar_tokenizer = Tokenizer(num_words=tar_vocab) \n",
    "tar_tokenizer.fit_on_texts(decoder_input_train)\n",
    "tar_tokenizer.fit_on_texts(decoder_target_train)\n",
    "\n",
    "# 텍스트 시퀀스를 정수 시퀀스로 변환\n",
    "decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train) \n",
    "decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n",
    "decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n",
    "decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n",
    "\n",
    "# 잘 변환되었는지 확인\n",
    "print('input')\n",
    "print('input ',decoder_input_train[:5])\n",
    "print('target')\n",
    "print('decoder ',decoder_target_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "91917ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "삭제할 훈련 데이터의 개수 : 19\n",
      "삭제할 테스트 데이터의 개수 : 3\n",
      "훈련 데이터의 개수 : 78314\n",
      "훈련 레이블의 개수 : 78314\n",
      "테스트 데이터의 개수 : 19580\n",
      "테스트 레이블의 개수 : 19580\n"
     ]
    }
   ],
   "source": [
    "drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n",
    "drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n",
    "\n",
    "print('삭제할 훈련 데이터의 개수 :', len(drop_train))\n",
    "print('삭제할 테스트 데이터의 개수 :', len(drop_test))\n",
    "\n",
    "encoder_input_train = [sentence for index, sentence in enumerate(encoder_input_train) if index not in drop_train]\n",
    "decoder_input_train = [sentence for index, sentence in enumerate(decoder_input_train) if index not in drop_train]\n",
    "decoder_target_train = [sentence for index, sentence in enumerate(decoder_target_train) if index not in drop_train]\n",
    "\n",
    "encoder_input_test = [sentence for index, sentence in enumerate(encoder_input_test) if index not in drop_test]\n",
    "decoder_input_test = [sentence for index, sentence in enumerate(decoder_input_test) if index not in drop_test]\n",
    "decoder_target_test = [sentence for index, sentence in enumerate(decoder_target_test) if index not in drop_test]\n",
    "\n",
    "print('훈련 데이터의 개수 :', len(encoder_input_train))\n",
    "print('훈련 레이블의 개수 :', len(decoder_input_train))\n",
    "print('테스트 데이터의 개수 :', len(encoder_input_test))\n",
    "print('테스트 레이블의 개수 :', len(decoder_input_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82207e6",
   "metadata": {},
   "source": [
    "## (6) 패딩하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a4164e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "패딩 완료!\n"
     ]
    }
   ],
   "source": [
    "encoder_input_train = pad_sequences(encoder_input_train, maxlen=text_max_len, padding='post')\n",
    "encoder_input_test = pad_sequences(encoder_input_test, maxlen=text_max_len, padding='post')\n",
    "decoder_input_train = pad_sequences(decoder_input_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_train = pad_sequences(decoder_target_train, maxlen=headlines_max_len, padding='post')\n",
    "decoder_input_test = pad_sequences(decoder_input_test, maxlen=headlines_max_len, padding='post')\n",
    "decoder_target_test = pad_sequences(decoder_target_test, maxlen=headlines_max_len, padding='post')\n",
    "print('패딩 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e94267d",
   "metadata": {},
   "source": [
    "# Step 3. 어텐션 메커니즘 사용하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6c9f6a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "# 인코더 설계 시작\n",
    "embedding_dim = 128\n",
    "hidden_size = 256\n",
    "\n",
    "# 인코더\n",
    "encoder_inputs = Input(shape=(text_max_len,))\n",
    "\n",
    "# 인코더의 임베딩 층\n",
    "enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n",
    "\n",
    "# 인코더의 LSTM 1\n",
    "encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4, recurrent_dropout = 0.4)\n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n",
    "\n",
    "# 인코더의 LSTM 2\n",
    "encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n",
    "\n",
    "# 인코더의 LSTM 3\n",
    "encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4, recurrent_dropout=0.4)\n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d236a4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    }
   ],
   "source": [
    "# 디코더 설계\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "\n",
    "# 디코더의 임베딩 층\n",
    "dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n",
    "dec_emb = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 디코더의 LSTM\n",
    "decoder_lstm = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4, recurrent_dropout=0.2)\n",
    "decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state=[state_h, state_c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cd078383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 62)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 62, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 62, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 62, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 62, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 2000)   514000      lstm_3[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 3,633,104\n",
      "Trainable params: 3,633,104\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_outputs) \n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab5672",
   "metadata": {},
   "source": [
    "## 어텐션 메커니즘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "00f38f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 62)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 62, 128)      1024000     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 62, 256), (N 394240      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 62, 256), (N 525312      lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 128)    256000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   [(None, 62, 256), (N 525312      lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, None, 256),  394240      embedding_1[0][0]                \n",
      "                                                                 lstm_2[0][1]                     \n",
      "                                                                 lstm_2[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "attention_layer (AdditiveAttent (None, None, 256)    256         lstm_3[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concat_layer (Concatenate)      (None, None, 512)    0           lstm_3[0][0]                     \n",
      "                                                                 attention_layer[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, None, 2000)   1026000     concat_layer[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,145,360\n",
      "Trainable params: 4,145,360\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import AdditiveAttention\n",
    "\n",
    "# 어텐션 층(어텐션 함수)\n",
    "attn_layer = AdditiveAttention(name='attention_layer')\n",
    "\n",
    "# 인코더와 디코더의 모든 time step의 hidden state를 어텐션 층에 전달하고 결과를 리턴\n",
    "attn_out = attn_layer([decoder_outputs, encoder_outputs])\n",
    "\n",
    "\n",
    "# 어텐션의 결과와 디코더의 hidden state들을 연결\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n",
    "decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)\n",
    "\n",
    "# 모델 정의\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a440f930",
   "metadata": {},
   "source": [
    "## 모델 훈련하기\n",
    "- EarlyStopping : 특정 조건이 충족되면 훈련을 멈추는 역할\n",
    "- 검증 데이터의 손실이 줄어들지 않고 증가하는 현상이 2회(patience=2) 관측되면 학습을 멈추도록 설정\n",
    "- 훈련 완료 후 훈련 데이터의 손실과 검증 데이터의 손실이 줄어드는 과정 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa4e5ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "306/306 [==============================] - 261s 825ms/step - loss: 3.6971 - val_loss: 3.4511\n",
      "Epoch 2/50\n",
      "306/306 [==============================] - 249s 815ms/step - loss: 3.2651 - val_loss: 3.0956\n",
      "Epoch 3/50\n",
      "306/306 [==============================] - 249s 815ms/step - loss: 2.9829 - val_loss: 2.8822\n",
      "Epoch 4/50\n",
      "306/306 [==============================] - 249s 813ms/step - loss: 2.7975 - val_loss: 2.7432\n",
      "Epoch 5/50\n",
      "306/306 [==============================] - 249s 812ms/step - loss: 2.6643 - val_loss: 2.6495\n",
      "Epoch 6/50\n",
      "306/306 [==============================] - 247s 809ms/step - loss: 2.5593 - val_loss: 2.5743\n",
      "Epoch 7/50\n",
      "306/306 [==============================] - 249s 814ms/step - loss: 2.4712 - val_loss: 2.5061\n",
      "Epoch 8/50\n",
      "306/306 [==============================] - 248s 810ms/step - loss: 2.3962 - val_loss: 2.4575\n",
      "Epoch 9/50\n",
      "306/306 [==============================] - 248s 810ms/step - loss: 2.3289 - val_loss: 2.4159\n",
      "Epoch 10/50\n",
      "306/306 [==============================] - 248s 810ms/step - loss: 2.2693 - val_loss: 2.3807\n",
      "Epoch 11/50\n",
      " 30/306 [=>............................] - ETA: 3:37 - loss: 2.2036"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "es = EarlyStopping(monitor='val_loss', patience=2, verbose=1)\n",
    "history = model.fit(x=[encoder_input_train, decoder_input_train], y=decoder_target_train, \\\n",
    "          validation_data=([encoder_input_test, decoder_input_test], decoder_target_test), \\\n",
    "          batch_size=256, callbacks=[es], epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c579f64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b62a6dc",
   "metadata": {},
   "source": [
    "## 인퍼런스 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f414a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_index_to_word = src_tokenizer.index_word # 원문 단어 집합에서 정수 -> 단어를 얻음\n",
    "tar_word_to_index = tar_tokenizer.word_index # 요약 단어 집합에서 단어 -> 정수를 얻음\n",
    "tar_index_to_word = tar_tokenizer.index_word # 요약 단어 집합에서 정수 -> 단어를 얻음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65900b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더 설계\n",
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "# 이전 시점의 상태들을 저장하는 텐서\n",
    "decoder_state_input_h = Input(shape=(hidden_size,))\n",
    "decoder_state_input_c = Input(shape=(hidden_size,))\n",
    "\n",
    "dec_emb2 = dec_emb_layer(decoder_inputs)\n",
    "\n",
    "# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n",
    "# 훈련 과정에서와 달리 LSTM의 리턴하는 은닉 상태와 셀 상태인 state_h와 state_c를 버리지 않음.\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fbaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 어텐션 함수\n",
    "decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n",
    "attn_out_inf = attn_layer([decoder_outputs2, decoder_hidden_state_input])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "\n",
    "# 디코더의 출력층\n",
    "decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat) \n",
    "\n",
    "# 최종 디코더 모델\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "    [decoder_outputs2] + [state_h2, state_c2])\n",
    "\n",
    "print('=3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90fcdda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # 입력으로부터 인코더의 상태를 얻음\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "\n",
    "     # <SOS>에 해당하는 토큰 생성\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = tar_word_to_index['sostoken']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n",
    "\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = tar_index_to_word[sampled_token_index]\n",
    "\n",
    "        if (sampled_token!='eostoken'):\n",
    "            decoded_sentence += ' '+sampled_token\n",
    "\n",
    "        #  <eos>에 도달하거나 최대 길이를 넘으면 중단.\n",
    "        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n",
    "            stop_condition = True\n",
    "\n",
    "        # 길이가 1인 타겟 시퀀스를 업데이트\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # 상태를 업데이트 합니다.\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac732db",
   "metadata": {},
   "source": [
    "## 모델 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4dee799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2text(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if (i!=0):\n",
    "            temp = temp + src_index_to_word[i]+' '\n",
    "    return temp\n",
    "\n",
    "# 요약문의 정수 시퀀스를 텍스트 시퀀스로 변환\n",
    "def seq2summary(input_seq):\n",
    "    temp=''\n",
    "    for i in input_seq:\n",
    "        if ((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n",
    "            temp = temp + tar_index_to_word[i] + ' '\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48b4986",
   "metadata": {},
   "source": [
    "# Step 4. 실제 결과와 요약문 비교하기 (추상적 요약)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de09b14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(50, 100):\n",
    "    print(\"원문 :\", seq2text(encoder_input_test[i]))\n",
    "    print(\"실제 요약 :\", seq2summary(decoder_input_test[i]))\n",
    "    print(\"예측 요약 :\", decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5987482",
   "metadata": {},
   "source": [
    "# Step 5. Summa을 이용해서 추출적 요약해보기\n",
    "## (1) 데이터 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351e24a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from summa.summarizer import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda43159",
   "metadata": {},
   "source": [
    "## (2) summarize 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae3cbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d28b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, ratio=0.005, split=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc7a1849",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Summary:')\n",
    "print(summarize(text, words=50))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc64d9",
   "metadata": {},
   "source": [
    "# 🤔회고🤔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4686bd71",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
